{"version":3,"sources":["../../../src/neural/NeuralDomainMapper.ts"],"sourcesContent":["/**\n * Neural Domain Mapper - GNN-style Domain Relationship Mapping\n * \n * Implements Graph Neural Network (GNN) architecture for mapping and analyzing\n * domain relationships, calculating cohesion scores, identifying cross-domain\n * dependencies, and providing predictive boundary optimization.\n * \n * This class enables advanced domain analysis and relationship mapping for\n * the Claude Flow orchestration system, supporting dynamic domain boundaries\n * and intelligent task routing based on learned patterns.\n * \n * @author Claude Flow Neural Team\n * @version 2.0.0\n * @since 2024-12-01\n */\n\nimport type {\n  Pattern,\n  TrainingData,\n  Prediction,\n  Adaptation,\n  AgenticHookContext,\n  PerformanceMetric,\n  PatternStore,\n  TrainingState,\n} from '../services/agentic-flow-hooks/types.js';\nimport { EventEmitter } from 'events';\n\n// ===== Core Types =====\n\n/**\n * Represents a domain node in the neural network graph\n */\nexport interface DomainNode {\n  /** Unique identifier for the domain */\n  id: string;\n  /** Human-readable domain name */\n  name: string;\n  /** Domain type classification */\n  type: 'functional' | 'technical' | 'business' | 'integration' | 'data' | 'ui' | 'api';\n  /** Node features vector for neural processing */\n  features: number[];\n  /** Domain-specific metadata */\n  metadata: {\n    size: number;\n    complexity: number;\n    stability: number;\n    dependencies: string[];\n    lastUpdated: number;\n    version: string;\n  };\n  /** Current activation state */\n  activation: number;\n  /** Learning parameters */\n  embedding: number[];\n}\n\n/**\n * Represents an edge connection between domains\n */\nexport interface DomainEdge {\n  /** Source domain ID */\n  source: string;\n  /** Target domain ID */\n  target: string;\n  /** Edge weight representing relationship strength */\n  weight: number;\n  /** Type of relationship */\n  type: 'dependency' | 'communication' | 'data-flow' | 'inheritance' | 'composition' | 'aggregation';\n  /** Edge features for neural processing */\n  features: number[];\n  /** Relationship metadata */\n  metadata: {\n    frequency: number;\n    latency: number;\n    reliability: number;\n    bandwidth: number;\n    direction: 'bidirectional' | 'unidirectional';\n  };\n}\n\n/**\n * Graph structure containing domains and their relationships\n */\nexport interface DomainGraph {\n  /** Collection of domain nodes */\n  nodes: Map<string, DomainNode>;\n  /** Collection of domain edges */\n  edges: Map<string, DomainEdge>;\n  /** Graph-level metadata */\n  metadata: {\n    created: number;\n    lastTraining: number;\n    version: string;\n    cohesionScore: number;\n    totalNodes: number;\n    totalEdges: number;\n  };\n}\n\n/**\n * Domain cohesion analysis result\n */\nexport interface CohesionAnalysis {\n  /** Overall cohesion score (0-1) */\n  overallScore: number;\n  /** Per-domain cohesion scores */\n  domainScores: Map<string, number>;\n  /** Cohesion factors breakdown */\n  factors: {\n    structural: number;\n    functional: number;\n    behavioral: number;\n    semantic: number;\n  };\n  /** Identified weak points */\n  weakPoints: Array<{\n    domainId: string;\n    score: number;\n    reason: string;\n    suggestions: string[];\n  }>;\n  /** Optimization recommendations */\n  recommendations: Array<{\n    type: 'restructure' | 'merge' | 'split' | 'strengthen';\n    target: string[];\n    impact: number;\n    confidence: number;\n  }>;\n}\n\n/**\n * Cross-domain dependency analysis result\n */\nexport interface DependencyAnalysis {\n  /** Dependency graph */\n  graph: Map<string, string[]>;\n  /** Circular dependencies detected */\n  circularDependencies: string[][];\n  /** Critical paths */\n  criticalPaths: Array<{\n    path: string[];\n    risk: number;\n    impact: number;\n  }>;\n  /** Dependency metrics */\n  metrics: {\n    averageInDegree: number;\n    averageOutDegree: number;\n    maxDepth: number;\n    cyclomaticComplexity: number;\n  };\n  /** Optimization suggestions */\n  optimizations: Array<{\n    type: 'break-cycle' | 'reduce-coupling' | 'add-abstraction';\n    affected: string[];\n    benefit: number;\n    effort: number;\n  }>;\n}\n\n/**\n * Boundary optimization configuration\n */\nexport interface BoundaryOptimization {\n  /** Proposed boundary changes */\n  proposals: Array<{\n    id: string;\n    type: 'merge' | 'split' | 'relocate' | 'abstract';\n    domains: string[];\n    newBoundary?: {\n      nodes: string[];\n      edges: DomainEdge[];\n    };\n    metrics: {\n      cohesionImprovement: number;\n      couplingReduction: number;\n      performanceImpact: number;\n      maintainabilityImpact: number;\n    };\n    confidence: number;\n  }>;\n  /** Overall optimization score */\n  optimizationScore: number;\n  /** Implementation priority */\n  priority: 'low' | 'medium' | 'high' | 'critical';\n}\n\n/**\n * GNN layer configuration\n */\nexport interface GNNLayerConfig {\n  /** Layer type */\n  type: 'gcn' | 'gat' | 'sage' | 'gin' | 'transformer';\n  /** Input feature dimension */\n  inputDim: number;\n  /** Output feature dimension */\n  outputDim: number;\n  /** Number of attention heads (for GAT) */\n  numHeads?: number;\n  /** Dropout rate */\n  dropout: number;\n  /** Activation function */\n  activation: 'relu' | 'tanh' | 'sigmoid' | 'gelu' | 'swish';\n  /** Normalization */\n  normalization?: 'batch' | 'layer' | 'graph';\n}\n\n/**\n * Neural Domain Mapper training configuration\n */\nexport interface TrainingConfig {\n  /** Learning rate */\n  learningRate: number;\n  /** Batch size */\n  batchSize: number;\n  /** Number of epochs */\n  epochs: number;\n  /** Optimizer type */\n  optimizer: 'adam' | 'sgd' | 'rmsprop' | 'adamw';\n  /** Loss function */\n  lossFunction: 'mse' | 'cross-entropy' | 'contrastive' | 'triplet';\n  /** Regularization */\n  regularization: {\n    l1: number;\n    l2: number;\n    dropout: number;\n  };\n  /** Early stopping */\n  earlyStoping: {\n    enabled: boolean;\n    patience: number;\n    minDelta: number;\n  };\n  /** Validation split */\n  validationSplit: number;\n}\n\n// ===== Main Class =====\n\n/**\n * Neural Domain Mapper - Advanced GNN-based domain relationship analysis\n * \n * This class implements a sophisticated Graph Neural Network architecture\n * for analyzing and optimizing domain relationships in complex systems.\n * It provides capabilities for:\n * \n * 1. Converting domain structures to graph representations\n * 2. Calculating domain cohesion scores using multiple metrics\n * 3. Identifying and analyzing cross-domain dependencies\n * 4. Providing predictive boundary optimization suggestions\n * 5. Training on domain relationship patterns\n * 6. Making inferences about optimal domain organization\n */\nexport class NeuralDomainMapper extends EventEmitter {\n  private graph: DomainGraph;\n  private layers: GNNLayerConfig[];\n  private trainingConfig: TrainingConfig;\n  private trainingState: TrainingState;\n  private patternStore: PatternStore;\n  private isTraining: boolean = false;\n  private modelVersion: string = '1.0.0';\n  private weights: Map<string, number[]> = new Map();\n  private biases: Map<string, number[]> = new Map();\n\n  /**\n   * Initialize the Neural Domain Mapper\n   * \n   * @param config Training configuration\n   * @param patternStore Pattern storage system\n   */\n  constructor(\n    config: Partial<TrainingConfig> = {},\n    patternStore?: PatternStore\n  ) {\n    super();\n    \n    this.trainingConfig = {\n      learningRate: 0.001,\n      batchSize: 32,\n      epochs: 100,\n      optimizer: 'adam',\n      lossFunction: 'mse',\n      regularization: {\n        l1: 0.0001,\n        l2: 0.0001,\n        dropout: 0.1,\n      },\n      earlyStoping: {\n        enabled: true,\n        patience: 10,\n        minDelta: 0.001,\n      },\n      validationSplit: 0.2,\n      ...config,\n    };\n\n    this.graph = {\n      nodes: new Map(),\n      edges: new Map(),\n      metadata: {\n        created: Date.now(),\n        lastTraining: 0,\n        version: this.modelVersion,\n        cohesionScore: 0,\n        totalNodes: 0,\n        totalEdges: 0,\n      },\n    };\n\n    this.layers = [\n      {\n        type: 'gcn',\n        inputDim: 64,\n        outputDim: 128,\n        dropout: 0.1,\n        activation: 'relu',\n        normalization: 'batch',\n      },\n      {\n        type: 'gat',\n        inputDim: 128,\n        outputDim: 64,\n        numHeads: 8,\n        dropout: 0.1,\n        activation: 'relu',\n        normalization: 'layer',\n      },\n      {\n        type: 'gcn',\n        inputDim: 64,\n        outputDim: 32,\n        dropout: 0.05,\n        activation: 'tanh',\n      },\n    ];\n\n    this.trainingState = {\n      epoch: 0,\n      loss: Infinity,\n      accuracy: 0,\n      learningRate: this.trainingConfig.learningRate,\n      optimizer: this.trainingConfig.optimizer,\n      checkpoints: [],\n    };\n\n    this.patternStore = patternStore || this.createDefaultPatternStore();\n    this.initializeWeights();\n  }\n\n  // ===== Domain to Graph Conversion =====\n\n  /**\n   * Convert domain structure to graph format\n   * \n   * @param domains Domain definitions\n   * @param relationships Domain relationships\n   * @returns Constructed domain graph\n   */\n  public convertToGraph(\n    domains: Array<{\n      id: string;\n      name: string;\n      type: DomainNode['type'];\n      metadata: any;\n    }>,\n    relationships: Array<{\n      source: string;\n      target: string;\n      type: DomainEdge['type'];\n      weight?: number;\n      metadata?: any;\n    }>\n  ): DomainGraph {\n    // Clear existing graph\n    this.graph.nodes.clear();\n    this.graph.edges.clear();\n\n    // Convert domains to nodes\n    for (const domain of domains) {\n      const node: DomainNode = {\n        id: domain.id,\n        name: domain.name,\n        type: domain.type,\n        features: this.extractDomainFeatures(domain),\n        metadata: {\n          size: domain.metadata?.size || 1,\n          complexity: domain.metadata?.complexity || 0.5,\n          stability: domain.metadata?.stability || 0.8,\n          dependencies: domain.metadata?.dependencies || [],\n          lastUpdated: domain.metadata?.lastUpdated || Date.now(),\n          version: domain.metadata?.version || '1.0.0',\n        },\n        activation: 0,\n        embedding: this.initializeNodeEmbedding(domain.id),\n      };\n      \n      this.graph.nodes.set(domain.id, node);\n    }\n\n    // Convert relationships to edges\n    for (const rel of relationships) {\n      const edgeId = `${rel.source}->${rel.target}`;\n      const edge: DomainEdge = {\n        source: rel.source,\n        target: rel.target,\n        weight: rel.weight || 1.0,\n        type: rel.type,\n        features: this.extractEdgeFeatures(rel),\n        metadata: {\n          frequency: rel.metadata?.frequency || 1,\n          latency: rel.metadata?.latency || 100,\n          reliability: rel.metadata?.reliability || 0.99,\n          bandwidth: rel.metadata?.bandwidth || 1000,\n          direction: rel.metadata?.direction || 'unidirectional',\n        },\n      };\n      \n      this.graph.edges.set(edgeId, edge);\n    }\n\n    // Update graph metadata\n    this.graph.metadata.totalNodes = this.graph.nodes.size;\n    this.graph.metadata.totalEdges = this.graph.edges.size;\n    this.graph.metadata.lastTraining = 0; // Reset training timestamp\n\n    this.emit('graph-updated', this.graph);\n    return this.graph;\n  }\n\n  /**\n   * Extract numerical features from domain definition\n   */\n  private extractDomainFeatures(domain: any): number[] {\n    const features: number[] = [];\n    \n    // Type encoding (one-hot)\n    const types = ['functional', 'technical', 'business', 'integration', 'data', 'ui', 'api'];\n    const typeEncoding = types.map(t => t === domain.type ? 1 : 0);\n    features.push(...typeEncoding);\n    \n    // Metadata features\n    features.push(\n      domain.metadata?.size || 1,\n      domain.metadata?.complexity || 0.5,\n      domain.metadata?.stability || 0.8,\n      (domain.metadata?.dependencies?.length || 0) / 10, // Normalized dependency count\n      Math.min((Date.now() - (domain.metadata?.lastUpdated || Date.now())) / (1000 * 60 * 60 * 24), 1), // Age in days, capped at 1\n    );\n    \n    // Pad to standard feature size\n    while (features.length < 64) {\n      features.push(0);\n    }\n    \n    return features.slice(0, 64); // Ensure consistent size\n  }\n\n  /**\n   * Extract numerical features from edge definition\n   */\n  private extractEdgeFeatures(relationship: any): number[] {\n    const features: number[] = [];\n    \n    // Type encoding\n    const types = ['dependency', 'communication', 'data-flow', 'inheritance', 'composition', 'aggregation'];\n    const typeEncoding = types.map(t => t === relationship.type ? 1 : 0);\n    features.push(...typeEncoding);\n    \n    // Metadata features\n    features.push(\n      relationship.metadata?.frequency || 1,\n      relationship.metadata?.latency || 100,\n      relationship.metadata?.reliability || 0.99,\n      relationship.metadata?.bandwidth || 1000,\n      relationship.metadata?.direction === 'bidirectional' ? 1 : 0,\n    );\n    \n    // Pad to standard feature size\n    while (features.length < 32) {\n      features.push(0);\n    }\n    \n    return features.slice(0, 32);\n  }\n\n  // ===== Domain Cohesion Analysis =====\n\n  /**\n   * Calculate comprehensive domain cohesion scores\n   * \n   * @returns Detailed cohesion analysis\n   */\n  public async calculateDomainCohesion(): Promise<CohesionAnalysis> {\n    const domainScores = new Map<string, number>();\n    const weakPoints: Array<{\n      domainId: string;\n      score: number;\n      reason: string;\n      suggestions: string[];\n    }> = [];\n\n    let totalStructural = 0;\n    let totalFunctional = 0;\n    let totalBehavioral = 0;\n    let totalSemantic = 0;\n\n    // Calculate per-domain cohesion\n    for (const [domainId, node] of this.graph.nodes) {\n      const structural = this.calculateStructuralCohesion(domainId);\n      const functional = this.calculateFunctionalCohesion(domainId);\n      const behavioral = this.calculateBehavioralCohesion(domainId);\n      const semantic = this.calculateSemanticCohesion(domainId);\n      \n      const domainScore = (structural + functional + behavioral + semantic) / 4;\n      domainScores.set(domainId, domainScore);\n      \n      totalStructural += structural;\n      totalFunctional += functional;\n      totalBehavioral += behavioral;\n      totalSemantic += semantic;\n      \n      // Identify weak points\n      if (domainScore < 0.6) {\n        const suggestions = this.generateCohesionSuggestions(domainId, {\n          structural,\n          functional,\n          behavioral,\n          semantic,\n        });\n        \n        weakPoints.push({\n          domainId,\n          score: domainScore,\n          reason: this.identifyWeaknessReason(structural, functional, behavioral, semantic),\n          suggestions,\n        });\n      }\n    }\n\n    const nodeCount = this.graph.nodes.size;\n    const overallScore = Array.from(domainScores.values()).reduce((sum, score) => sum + score, 0) / nodeCount;\n    \n    const analysis: CohesionAnalysis = {\n      overallScore,\n      domainScores,\n      factors: {\n        structural: totalStructural / nodeCount,\n        functional: totalFunctional / nodeCount,\n        behavioral: totalBehavioral / nodeCount,\n        semantic: totalSemantic / nodeCount,\n      },\n      weakPoints,\n      recommendations: await this.generateCohesionRecommendations(domainScores, weakPoints),\n    };\n\n    // Update graph metadata\n    this.graph.metadata.cohesionScore = overallScore;\n    \n    this.emit('cohesion-calculated', analysis);\n    return analysis;\n  }\n\n  /**\n   * Calculate structural cohesion based on graph connectivity\n   */\n  private calculateStructuralCohesion(domainId: string): number {\n    const node = this.graph.nodes.get(domainId);\n    if (!node) return 0;\n\n    const outgoingEdges = Array.from(this.graph.edges.values()).filter(e => e.source === domainId);\n    const incomingEdges = Array.from(this.graph.edges.values()).filter(e => e.target === domainId);\n    \n    const totalEdges = outgoingEdges.length + incomingEdges.length;\n    const maxPossibleEdges = (this.graph.nodes.size - 1) * 2; // Bidirectional\n    \n    const connectivity = totalEdges / maxPossibleEdges;\n    \n    // Consider edge weights\n    const weightedConnectivity = (\n      outgoingEdges.reduce((sum, e) => sum + e.weight, 0) +\n      incomingEdges.reduce((sum, e) => sum + e.weight, 0)\n    ) / (totalEdges || 1);\n    \n    return Math.min((connectivity + weightedConnectivity) / 2, 1);\n  }\n\n  /**\n   * Calculate functional cohesion based on domain purpose alignment\n   */\n  private calculateFunctionalCohesion(domainId: string): number {\n    const node = this.graph.nodes.get(domainId);\n    if (!node) return 0;\n\n    // Analyze connected domains for functional similarity\n    const connectedDomains = this.getConnectedDomains(domainId);\n    const sameTypePenalty = connectedDomains.filter(d => d.type === node.type).length / (connectedDomains.length || 1);\n    \n    // Consider domain complexity and size alignment\n    const avgComplexity = connectedDomains.reduce((sum, d) => sum + d.metadata.complexity, 0) / (connectedDomains.length || 1);\n    const complexityAlignment = 1 - Math.abs(node.metadata.complexity - avgComplexity);\n    \n    return (sameTypePenalty * 0.6 + complexityAlignment * 0.4);\n  }\n\n  /**\n   * Calculate behavioral cohesion based on interaction patterns\n   */\n  private calculateBehavioralCohesion(domainId: string): number {\n    const relatedEdges = Array.from(this.graph.edges.values()).filter(\n      e => e.source === domainId || e.target === domainId\n    );\n    \n    if (relatedEdges.length === 0) return 0.5; // Neutral for isolated domains\n    \n    // Analyze interaction frequency and reliability\n    const avgFrequency = relatedEdges.reduce((sum, e) => sum + e.metadata.frequency, 0) / relatedEdges.length;\n    const avgReliability = relatedEdges.reduce((sum, e) => sum + e.metadata.reliability, 0) / relatedEdges.length;\n    const avgLatency = relatedEdges.reduce((sum, e) => sum + e.metadata.latency, 0) / relatedEdges.length;\n    \n    // Normalize and combine metrics\n    const frequencyScore = Math.min(avgFrequency / 10, 1); // Assume 10 is high frequency\n    const reliabilityScore = avgReliability;\n    const latencyScore = Math.max(0, 1 - avgLatency / 1000); // Assume 1000ms is poor latency\n    \n    return (frequencyScore + reliabilityScore + latencyScore) / 3;\n  }\n\n  /**\n   * Calculate semantic cohesion based on domain naming and metadata\n   */\n  private calculateSemanticCohesion(domainId: string): number {\n    const node = this.graph.nodes.get(domainId);\n    if (!node) return 0;\n\n    const connectedDomains = this.getConnectedDomains(domainId);\n    \n    // Analyze naming similarity (simplified semantic analysis)\n    let semanticScore = 0;\n    for (const connectedDomain of connectedDomains) {\n      const nameSimilarity = this.calculateNameSimilarity(node.name, connectedDomain.name);\n      const typeSimilarity = node.type === connectedDomain.type ? 1 : 0.5;\n      semanticScore += (nameSimilarity + typeSimilarity) / 2;\n    }\n    \n    return connectedDomains.length > 0 ? semanticScore / connectedDomains.length : 0.5;\n  }\n\n  /**\n   * Get domains connected to the specified domain\n   */\n  private getConnectedDomains(domainId: string): DomainNode[] {\n    const connectedIds = new Set<string>();\n    \n    for (const edge of this.graph.edges.values()) {\n      if (edge.source === domainId) {\n        connectedIds.add(edge.target);\n      } else if (edge.target === domainId) {\n        connectedIds.add(edge.source);\n      }\n    }\n    \n    return Array.from(connectedIds)\n      .map(id => this.graph.nodes.get(id))\n      .filter(Boolean) as DomainNode[];\n  }\n\n  /**\n   * Calculate name similarity between two domain names\n   */\n  private calculateNameSimilarity(name1: string, name2: string): number {\n    const words1 = name1.toLowerCase().split(/[\\s\\-_]+/);\n    const words2 = name2.toLowerCase().split(/[\\s\\-_]+/);\n    \n    const commonWords = words1.filter(w => words2.includes(w));\n    const totalWords = new Set([...words1, ...words2]).size;\n    \n    return totalWords > 0 ? commonWords.length / totalWords : 0;\n  }\n\n  // ===== Cross-Domain Dependency Analysis =====\n\n  /**\n   * Identify and analyze cross-domain dependencies\n   * \n   * @returns Comprehensive dependency analysis\n   */\n  public async identifyCrossDomainDependencies(): Promise<DependencyAnalysis> {\n    const dependencyGraph = new Map<string, string[]>();\n    const circularDependencies: string[][] = [];\n    const criticalPaths: Array<{\n      path: string[];\n      risk: number;\n      impact: number;\n    }> = [];\n\n    // Build dependency graph\n    for (const [nodeId] of this.graph.nodes) {\n      const dependencies: string[] = [];\n      \n      for (const edge of this.graph.edges.values()) {\n        if (edge.source === nodeId && edge.type === 'dependency') {\n          dependencies.push(edge.target);\n        }\n      }\n      \n      dependencyGraph.set(nodeId, dependencies);\n    }\n\n    // Detect circular dependencies\n    const visited = new Set<string>();\n    const recursionStack = new Set<string>();\n\n    const detectCircularDFS = (nodeId: string, path: string[]): void => {\n      visited.add(nodeId);\n      recursionStack.add(nodeId);\n      path.push(nodeId);\n\n      const dependencies = dependencyGraph.get(nodeId) || [];\n      for (const depId of dependencies) {\n        if (!visited.has(depId)) {\n          detectCircularDFS(depId, [...path]);\n        } else if (recursionStack.has(depId)) {\n          // Found circular dependency\n          const cycleStart = path.indexOf(depId);\n          const cycle = path.slice(cycleStart);\n          circularDependencies.push([...cycle, depId]);\n        }\n      }\n\n      recursionStack.delete(nodeId);\n    };\n\n    for (const [nodeId] of this.graph.nodes) {\n      if (!visited.has(nodeId)) {\n        detectCircularDFS(nodeId, []);\n      }\n    }\n\n    // Identify critical paths\n    const calculateRisk = (path: string[]): number => {\n      let totalRisk = 0;\n      for (let i = 0; i < path.length - 1; i++) {\n        const edgeId = `${path[i]}->${path[i + 1]}`;\n        const edge = this.graph.edges.get(edgeId);\n        if (edge) {\n          // Risk based on reliability (inverted) and criticality\n          const reliability = edge.metadata.reliability;\n          const criticality = 1 - reliability;\n          totalRisk += criticality;\n        }\n      }\n      return totalRisk / (path.length - 1);\n    };\n\n    const calculateImpact = (path: string[]): number => {\n      // Impact based on number of affected domains\n      const affectedDomains = new Set<string>();\n      \n      for (const nodeId of path) {\n        // Find all domains that depend on nodes in this path\n        for (const [depId, deps] of dependencyGraph) {\n          if (deps.includes(nodeId)) {\n            affectedDomains.add(depId);\n          }\n        }\n      }\n      \n      return affectedDomains.size / this.graph.nodes.size;\n    };\n\n    // Find longest dependency chains as critical paths\n    const findLongestPaths = (nodeId: string, visited: Set<string>, path: string[]): void => {\n      if (path.length > 3) { // Consider paths longer than 3 as potentially critical\n        const risk = calculateRisk(path);\n        const impact = calculateImpact(path);\n        \n        if (risk > 0.3 || impact > 0.2) {\n          criticalPaths.push({\n            path: [...path],\n            risk,\n            impact,\n          });\n        }\n      }\n\n      const dependencies = dependencyGraph.get(nodeId) || [];\n      for (const depId of dependencies) {\n        if (!visited.has(depId)) {\n          visited.add(depId);\n          findLongestPaths(depId, visited, [...path, depId]);\n          visited.delete(depId);\n        }\n      }\n    };\n\n    for (const [nodeId] of this.graph.nodes) {\n      const visited = new Set([nodeId]);\n      findLongestPaths(nodeId, visited, [nodeId]);\n    }\n\n    // Calculate metrics\n    const inDegrees = new Map<string, number>();\n    const outDegrees = new Map<string, number>();\n    \n    for (const [nodeId] of this.graph.nodes) {\n      inDegrees.set(nodeId, 0);\n      outDegrees.set(nodeId, 0);\n    }\n    \n    for (const deps of dependencyGraph.values()) {\n      outDegrees.set(nodeId, deps.length);\n      for (const depId of deps) {\n        inDegrees.set(depId, (inDegrees.get(depId) || 0) + 1);\n      }\n    }\n\n    const averageInDegree = Array.from(inDegrees.values()).reduce((sum, deg) => sum + deg, 0) / this.graph.nodes.size;\n    const averageOutDegree = Array.from(outDegrees.values()).reduce((sum, deg) => sum + deg, 0) / this.graph.nodes.size;\n    \n    // Calculate maximum depth\n    const calculateMaxDepth = (nodeId: string, visited: Set<string>): number => {\n      if (visited.has(nodeId)) return 0;\n      visited.add(nodeId);\n      \n      const dependencies = dependencyGraph.get(nodeId) || [];\n      if (dependencies.length === 0) return 1;\n      \n      const depths = dependencies.map(depId => calculateMaxDepth(depId, new Set(visited)));\n      return 1 + Math.max(...depths, 0);\n    };\n\n    const depths = Array.from(this.graph.nodes.keys()).map(nodeId => calculateMaxDepth(nodeId, new Set()));\n    const maxDepth = Math.max(...depths, 0);\n\n    // Cyclomatic complexity (simplified)\n    const cyclomaticComplexity = this.graph.edges.size - this.graph.nodes.size + 2;\n\n    const analysis: DependencyAnalysis = {\n      graph: dependencyGraph,\n      circularDependencies,\n      criticalPaths: criticalPaths.sort((a, b) => (b.risk + b.impact) - (a.risk + a.impact)).slice(0, 10),\n      metrics: {\n        averageInDegree,\n        averageOutDegree,\n        maxDepth,\n        cyclomaticComplexity,\n      },\n      optimizations: await this.generateDependencyOptimizations(\n        dependencyGraph,\n        circularDependencies,\n        criticalPaths\n      ),\n    };\n\n    this.emit('dependencies-analyzed', analysis);\n    return analysis;\n  }\n\n  // ===== Predictive Boundary Optimization =====\n\n  /**\n   * Provide predictive boundary optimization suggestions\n   * \n   * @returns Boundary optimization recommendations\n   */\n  public async provideBoundaryOptimization(): Promise<BoundaryOptimization> {\n    const proposals: BoundaryOptimization['proposals'] = [];\n    \n    // Analyze current boundaries and identify optimization opportunities\n    const cohesionAnalysis = await this.calculateDomainCohesion();\n    const dependencyAnalysis = await this.identifyCrossDomainDependencies();\n    \n    // Generate merge proposals for highly coupled domains\n    await this.generateMergeProposals(proposals, cohesionAnalysis, dependencyAnalysis);\n    \n    // Generate split proposals for low-cohesion domains\n    await this.generateSplitProposals(proposals, cohesionAnalysis, dependencyAnalysis);\n    \n    // Generate relocation proposals for misplaced functionality\n    await this.generateRelocationProposals(proposals, cohesionAnalysis, dependencyAnalysis);\n    \n    // Generate abstraction proposals for common patterns\n    await this.generateAbstractionProposals(proposals, cohesionAnalysis, dependencyAnalysis);\n    \n    // Calculate overall optimization score\n    const optimizationScore = this.calculateOptimizationScore(proposals);\n    \n    // Determine priority based on current system health\n    const priority = this.determinePriority(cohesionAnalysis, dependencyAnalysis, optimizationScore);\n    \n    const optimization: BoundaryOptimization = {\n      proposals: proposals.sort((a, b) => b.confidence - a.confidence).slice(0, 20),\n      optimizationScore,\n      priority,\n    };\n\n    this.emit('optimization-generated', optimization);\n    return optimization;\n  }\n\n  // ===== Training Methods =====\n\n  /**\n   * Train the neural network on domain relationship patterns\n   * \n   * @param trainingData Training dataset\n   * @param validationData Validation dataset\n   * @returns Training results\n   */\n  public async train(\n    trainingData: TrainingData,\n    validationData?: TrainingData\n  ): Promise<{\n    finalAccuracy: number;\n    trainingHistory: Array<{\n      epoch: number;\n      loss: number;\n      accuracy: number;\n      validationLoss?: number;\n      validationAccuracy?: number;\n    }>;\n    bestModel: {\n      weights: Map<string, number[]>;\n      biases: Map<string, number[]>;\n    };\n  }> {\n    if (this.isTraining) {\n      throw new Error('Training already in progress');\n    }\n\n    this.isTraining = true;\n    this.emit('training-started', { trainingData, validationData });\n\n    try {\n      const trainingHistory: Array<{\n        epoch: number;\n        loss: number;\n        accuracy: number;\n        validationLoss?: number;\n        validationAccuracy?: number;\n      }> = [];\n\n      let bestAccuracy = 0;\n      let bestWeights = new Map(this.weights);\n      let bestBiases = new Map(this.biases);\n      let patienceCounter = 0;\n\n      // Training loop\n      for (let epoch = 0; epoch < this.trainingConfig.epochs; epoch++) {\n        this.trainingState.epoch = epoch;\n        \n        // Forward pass and backpropagation\n        const { loss, accuracy } = await this.trainEpoch(trainingData);\n        \n        // Validation\n        let validationLoss: number | undefined;\n        let validationAccuracy: number | undefined;\n        \n        if (validationData) {\n          const validationResults = await this.validateModel(validationData);\n          validationLoss = validationResults.loss;\n          validationAccuracy = validationResults.accuracy;\n        }\n\n        // Update training state\n        this.trainingState.loss = loss;\n        this.trainingState.accuracy = accuracy;\n        this.trainingState.validationLoss = validationLoss;\n        this.trainingState.validationAccuracy = validationAccuracy;\n\n        const epochResult = {\n          epoch,\n          loss,\n          accuracy,\n          validationLoss,\n          validationAccuracy,\n        };\n        trainingHistory.push(epochResult);\n\n        // Check for improvement\n        const currentAccuracy = validationAccuracy || accuracy;\n        if (currentAccuracy > bestAccuracy + this.trainingConfig.earlyStoping.minDelta) {\n          bestAccuracy = currentAccuracy;\n          bestWeights = new Map(this.weights);\n          bestBiases = new Map(this.biases);\n          patienceCounter = 0;\n        } else {\n          patienceCounter++;\n        }\n\n        // Early stopping\n        if (\n          this.trainingConfig.earlyStoping.enabled &&\n          patienceCounter >= this.trainingConfig.earlyStoping.patience\n        ) {\n          console.log(`Early stopping at epoch ${epoch}`);\n          break;\n        }\n\n        // Learning rate scheduling\n        if (epoch > 0 && epoch % 20 === 0) {\n          this.trainingConfig.learningRate *= 0.9;\n          this.trainingState.learningRate = this.trainingConfig.learningRate;\n        }\n\n        this.emit('epoch-completed', epochResult);\n      }\n\n      // Restore best model\n      this.weights = bestWeights;\n      this.biases = bestBiases;\n      \n      // Update graph metadata\n      this.graph.metadata.lastTraining = Date.now();\n\n      const result = {\n        finalAccuracy: bestAccuracy,\n        trainingHistory,\n        bestModel: {\n          weights: bestWeights,\n          biases: bestBiases,\n        },\n      };\n\n      this.emit('training-completed', result);\n      return result;\n\n    } finally {\n      this.isTraining = false;\n    }\n  }\n\n  /**\n   * Train a single epoch\n   */\n  private async trainEpoch(trainingData: TrainingData): Promise<{\n    loss: number;\n    accuracy: number;\n  }> {\n    const batchSize = this.trainingConfig.batchSize;\n    let totalLoss = 0;\n    let correct = 0;\n    let total = 0;\n\n    // Shuffle training data\n    const indices = Array.from({ length: trainingData.inputs.length }, (_, i) => i);\n    this.shuffleArray(indices);\n\n    // Process batches\n    for (let i = 0; i < indices.length; i += batchSize) {\n      const batchIndices = indices.slice(i, i + batchSize);\n      const batchInputs = batchIndices.map(idx => trainingData.inputs[idx]);\n      const batchTargets = batchIndices.map(idx => trainingData.outputs[idx]);\n\n      const { loss, accuracy } = await this.processBatch(batchInputs, batchTargets);\n      \n      totalLoss += loss;\n      correct += accuracy * batchIndices.length;\n      total += batchIndices.length;\n    }\n\n    return {\n      loss: totalLoss / Math.ceil(indices.length / batchSize),\n      accuracy: correct / total,\n    };\n  }\n\n  /**\n   * Process a single batch\n   */\n  private async processBatch(\n    inputs: any[],\n    targets: any[]\n  ): Promise<{ loss: number; accuracy: number }> {\n    // Forward pass\n    const predictions = inputs.map(input => this.forwardPass(input));\n    \n    // Calculate loss\n    const loss = this.calculateLoss(predictions, targets);\n    \n    // Calculate accuracy\n    const accuracy = this.calculateAccuracy(predictions, targets);\n    \n    // Backward pass\n    await this.backwardPass(inputs, predictions, targets);\n    \n    return { loss, accuracy };\n  }\n\n  /**\n   * Forward pass through the network\n   */\n  private forwardPass(input: any): number[] {\n    let activation = this.preprocessInput(input);\n    \n    // Process through each layer\n    for (let i = 0; i < this.layers.length; i++) {\n      const layerConfig = this.layers[i];\n      const weights = this.weights.get(`layer_${i}`) || [];\n      const biases = this.biases.get(`layer_${i}`) || [];\n      \n      activation = this.processLayer(activation, weights, biases, layerConfig);\n    }\n    \n    return activation;\n  }\n\n  /**\n   * Backward pass for gradient calculation and weight updates\n   */\n  private async backwardPass(\n    inputs: any[],\n    predictions: number[][],\n    targets: any[]\n  ): Promise<void> {\n    // Calculate output gradients\n    const outputGradients = this.calculateOutputGradients(predictions, targets);\n    \n    // Backpropagate through layers\n    let gradients = outputGradients;\n    \n    for (let i = this.layers.length - 1; i >= 0; i--) {\n      const layerConfig = this.layers[i];\n      const weights = this.weights.get(`layer_${i}`) || [];\n      const biases = this.biases.get(`layer_${i}`) || [];\n      \n      const { weightGradients, biasGradients, inputGradients } = \n        this.calculateLayerGradients(gradients, weights, biases, layerConfig);\n      \n      // Update weights and biases\n      this.updateWeights(`layer_${i}`, weights, weightGradients);\n      this.updateBiases(`layer_${i}`, biases, biasGradients);\n      \n      gradients = inputGradients;\n    }\n  }\n\n  // ===== Inference Methods =====\n\n  /**\n   * Make predictions using the trained model\n   * \n   * @param input Input data for prediction\n   * @returns Prediction results\n   */\n  public async predict(input: any): Promise<Prediction> {\n    if (this.isTraining) {\n      throw new Error('Cannot make predictions during training');\n    }\n\n    const output = this.forwardPass(input);\n    const confidence = this.calculatePredictionConfidence(output);\n    \n    // Generate alternatives using dropout or ensemble\n    const alternatives = await this.generateAlternativePredictions(input, 5);\n    \n    const prediction: Prediction = {\n      input,\n      output,\n      confidence,\n      alternatives,\n    };\n\n    this.emit('prediction-made', prediction);\n    return prediction;\n  }\n\n  /**\n   * Analyze domain relationships and suggest optimizations\n   * \n   * @param domains Domain configuration to analyze\n   * @returns Analysis results with optimization suggestions\n   */\n  public async analyzeDomains(domains: DomainGraph): Promise<{\n    cohesion: CohesionAnalysis;\n    dependencies: DependencyAnalysis;\n    optimization: BoundaryOptimization;\n    recommendations: string[];\n  }> {\n    // Update internal graph\n    this.graph = { ...domains };\n    \n    // Perform comprehensive analysis\n    const [cohesion, dependencies, optimization] = await Promise.all([\n      this.calculateDomainCohesion(),\n      this.identifyCrossDomainDependencies(),\n      this.provideBoundaryOptimization(),\n    ]);\n    \n    // Generate high-level recommendations\n    const recommendations = this.generateHighLevelRecommendations(\n      cohesion,\n      dependencies,\n      optimization\n    );\n    \n    const analysis = {\n      cohesion,\n      dependencies,\n      optimization,\n      recommendations,\n    };\n\n    this.emit('domains-analyzed', analysis);\n    return analysis;\n  }\n\n  // ===== Helper Methods =====\n\n  private createDefaultPatternStore(): PatternStore {\n    const patterns = new Map<string, Pattern>();\n    \n    return {\n      add: (pattern: Pattern) => patterns.set(pattern.id, pattern),\n      get: (id: string) => patterns.get(id),\n      findSimilar: (pattern: Partial<Pattern>, threshold: number) => {\n        return Array.from(patterns.values()).filter(p => \n          this.calculatePatternSimilarity(p, pattern) >= threshold\n        );\n      },\n      getByType: (type: Pattern['type']) => {\n        return Array.from(patterns.values()).filter(p => p.type === type);\n      },\n      prune: (maxAge: number) => {\n        const cutoff = Date.now() - maxAge;\n        for (const [id, pattern] of patterns) {\n          if (Date.now() - maxAge > cutoff) {\n            patterns.delete(id);\n          }\n        }\n      },\n      export: () => Array.from(patterns.values()),\n      import: (importedPatterns: Pattern[]) => {\n        for (const pattern of importedPatterns) {\n          patterns.set(pattern.id, pattern);\n        }\n      },\n    };\n  }\n\n  private initializeNodeEmbedding(nodeId: string): number[] {\n    return Array.from({ length: 32 }, () => (Math.random() - 0.5) * 0.1);\n  }\n\n  private initializeWeights(): void {\n    for (let i = 0; i < this.layers.length; i++) {\n      const layer = this.layers[i];\n      const inputDim = i === 0 ? 64 : this.layers[i - 1].outputDim;\n      const outputDim = layer.outputDim;\n      \n      // Xavier/Glorot initialization\n      const limit = Math.sqrt(6 / (inputDim + outputDim));\n      const weights = Array.from(\n        { length: inputDim * outputDim },\n        () => (Math.random() - 0.5) * 2 * limit\n      );\n      \n      const biases = Array.from({ length: outputDim }, () => 0);\n      \n      this.weights.set(`layer_${i}`, weights);\n      this.biases.set(`layer_${i}`, biases);\n    }\n  }\n\n  private shuffleArray<T>(array: T[]): void {\n    for (let i = array.length - 1; i > 0; i--) {\n      const j = Math.floor(Math.random() * (i + 1));\n      [array[i], array[j]] = [array[j], array[i]];\n    }\n  }\n\n  private preprocessInput(input: any): number[] {\n    // Convert input to numerical features\n    if (typeof input === 'object' && input.features) {\n      return input.features;\n    }\n    \n    // Default preprocessing\n    return Array.from({ length: 64 }, () => 0);\n  }\n\n  private processLayer(\n    input: number[],\n    weights: number[],\n    biases: number[],\n    config: GNNLayerConfig\n  ): number[] {\n    // Matrix multiplication: input * weights + biases\n    const output = new Array(config.outputDim).fill(0);\n    \n    for (let i = 0; i < config.outputDim; i++) {\n      let sum = biases[i] || 0;\n      for (let j = 0; j < input.length; j++) {\n        const weightIndex = j * config.outputDim + i;\n        sum += input[j] * (weights[weightIndex] || 0);\n      }\n      output[i] = this.applyActivation(sum, config.activation);\n    }\n    \n    // Apply dropout during training\n    if (this.isTraining && config.dropout > 0) {\n      for (let i = 0; i < output.length; i++) {\n        if (Math.random() < config.dropout) {\n          output[i] = 0;\n        }\n      }\n    }\n    \n    return output;\n  }\n\n  private applyActivation(x: number, activation: string): number {\n    switch (activation) {\n      case 'relu':\n        return Math.max(0, x);\n      case 'tanh':\n        return Math.tanh(x);\n      case 'sigmoid':\n        return 1 / (1 + Math.exp(-x));\n      case 'gelu':\n        return 0.5 * x * (1 + Math.tanh(Math.sqrt(2 / Math.PI) * (x + 0.044715 * Math.pow(x, 3))));\n      case 'swish':\n        return x / (1 + Math.exp(-x));\n      default:\n        return x;\n    }\n  }\n\n  private calculateLoss(predictions: number[][], targets: any[]): number {\n    let totalLoss = 0;\n    \n    for (let i = 0; i < predictions.length; i++) {\n      const pred = predictions[i];\n      const target = Array.isArray(targets[i]) ? targets[i] : [targets[i]];\n      \n      // Mean squared error\n      for (let j = 0; j < Math.min(pred.length, target.length); j++) {\n        const diff = pred[j] - target[j];\n        totalLoss += diff * diff;\n      }\n    }\n    \n    return totalLoss / predictions.length;\n  }\n\n  private calculateAccuracy(predictions: number[][], targets: any[]): number {\n    let correct = 0;\n    \n    for (let i = 0; i < predictions.length; i++) {\n      const pred = predictions[i];\n      const target = Array.isArray(targets[i]) ? targets[i] : [targets[i]];\n      \n      // Simple threshold-based accuracy for regression\n      let sampleCorrect = true;\n      for (let j = 0; j < Math.min(pred.length, target.length); j++) {\n        if (Math.abs(pred[j] - target[j]) > 0.1) {\n          sampleCorrect = false;\n          break;\n        }\n      }\n      \n      if (sampleCorrect) correct++;\n    }\n    \n    return correct / predictions.length;\n  }\n\n  private calculateOutputGradients(predictions: number[][], targets: any[]): number[][] {\n    const gradients: number[][] = [];\n    \n    for (let i = 0; i < predictions.length; i++) {\n      const pred = predictions[i];\n      const target = Array.isArray(targets[i]) ? targets[i] : [targets[i]];\n      const sampleGradients: number[] = [];\n      \n      for (let j = 0; j < pred.length; j++) {\n        const targetVal = j < target.length ? target[j] : 0;\n        sampleGradients.push(2 * (pred[j] - targetVal));\n      }\n      \n      gradients.push(sampleGradients);\n    }\n    \n    return gradients;\n  }\n\n  private calculateLayerGradients(\n    outputGradients: number[][],\n    weights: number[],\n    biases: number[],\n    config: GNNLayerConfig\n  ): {\n    weightGradients: number[];\n    biasGradients: number[];\n    inputGradients: number[][];\n  } {\n    // Simplified gradient calculation\n    const weightGradients = new Array(weights.length).fill(0);\n    const biasGradients = new Array(biases.length).fill(0);\n    const inputGradients: number[][] = [];\n    \n    // This is a simplified implementation\n    // In practice, you'd need proper matrix operations and chain rule application\n    \n    for (let i = 0; i < outputGradients.length; i++) {\n      const sampleInputGradients = new Array(config.inputDim).fill(0);\n      \n      for (let j = 0; j < outputGradients[i].length; j++) {\n        const grad = outputGradients[i][j];\n        \n        // Bias gradients\n        biasGradients[j] += grad;\n        \n        // Weight and input gradients would require activation functions and inputs\n        // This is simplified for demonstration\n      }\n      \n      inputGradients.push(sampleInputGradients);\n    }\n    \n    return { weightGradients, biasGradients, inputGradients };\n  }\n\n  private updateWeights(layerId: string, weights: number[], gradients: number[]): void {\n    const lr = this.trainingState.learningRate;\n    const l2 = this.trainingConfig.regularization.l2;\n    \n    for (let i = 0; i < weights.length && i < gradients.length; i++) {\n      weights[i] -= lr * (gradients[i] + l2 * weights[i]);\n    }\n    \n    this.weights.set(layerId, weights);\n  }\n\n  private updateBiases(layerId: string, biases: number[], gradients: number[]): void {\n    const lr = this.trainingState.learningRate;\n    \n    for (let i = 0; i < biases.length && i < gradients.length; i++) {\n      biases[i] -= lr * gradients[i];\n    }\n    \n    this.biases.set(layerId, biases);\n  }\n\n  private async validateModel(validationData: TrainingData): Promise<{\n    loss: number;\n    accuracy: number;\n  }> {\n    const predictions = validationData.inputs.map(input => this.forwardPass(input));\n    const loss = this.calculateLoss(predictions, validationData.outputs);\n    const accuracy = this.calculateAccuracy(predictions, validationData.outputs);\n    \n    return { loss, accuracy };\n  }\n\n  private calculatePredictionConfidence(output: number[]): number {\n    // Calculate confidence based on output certainty\n    const maxVal = Math.max(...output);\n    const minVal = Math.min(...output);\n    const range = maxVal - minVal;\n    \n    // Higher range indicates more confident prediction\n    return Math.min(range, 1);\n  }\n\n  private async generateAlternativePredictions(\n    input: any,\n    count: number\n  ): Promise<Array<{ output: any; confidence: number }>> {\n    const alternatives: Array<{ output: any; confidence: number }> = [];\n    \n    // Generate alternatives using noise injection\n    for (let i = 0; i < count; i++) {\n      const noisyInput = this.addNoiseToInput(input, 0.1);\n      const output = this.forwardPass(noisyInput);\n      const confidence = this.calculatePredictionConfidence(output);\n      \n      alternatives.push({ output, confidence });\n    }\n    \n    return alternatives.sort((a, b) => b.confidence - a.confidence);\n  }\n\n  private addNoiseToInput(input: any, noiseLevel: number): any {\n    if (typeof input === 'object' && input.features) {\n      const noisyFeatures = input.features.map((f: number) => \n        f + (Math.random() - 0.5) * noiseLevel\n      );\n      return { ...input, features: noisyFeatures };\n    }\n    \n    return input;\n  }\n\n  private calculatePatternSimilarity(p1: Pattern, p2: Partial<Pattern>): number {\n    // Simplified similarity calculation\n    let similarity = 0;\n    let factors = 0;\n    \n    if (p1.type === p2.type) {\n      similarity += 0.3;\n    }\n    factors++;\n    \n    if (p2.confidence !== undefined) {\n      similarity += 1 - Math.abs(p1.confidence - p2.confidence);\n      factors++;\n    }\n    \n    return similarity / factors;\n  }\n\n  // Additional helper methods would be implemented here for:\n  // - generateCohesionSuggestions\n  // - identifyWeaknessReason\n  // - generateCohesionRecommendations\n  // - generateDependencyOptimizations\n  // - generateMergeProposals\n  // - generateSplitProposals\n  // - generateRelocationProposals\n  // - generateAbstractionProposals\n  // - calculateOptimizationScore\n  // - determinePriority\n  // - generateHighLevelRecommendations\n\n  /**\n   * Get current model statistics\n   */\n  public getModelStats(): {\n    graphSize: { nodes: number; edges: number };\n    trainingState: TrainingState;\n    modelVersion: string;\n    lastTraining: number;\n    cohesionScore: number;\n  } {\n    return {\n      graphSize: {\n        nodes: this.graph.nodes.size,\n        edges: this.graph.edges.size,\n      },\n      trainingState: { ...this.trainingState },\n      modelVersion: this.modelVersion,\n      lastTraining: this.graph.metadata.lastTraining,\n      cohesionScore: this.graph.metadata.cohesionScore,\n    };\n  }\n\n  /**\n   * Export model state for persistence\n   */\n  public exportModel(): {\n    graph: DomainGraph;\n    weights: Record<string, number[]>;\n    biases: Record<string, number[]>;\n    trainingState: TrainingState;\n    config: TrainingConfig;\n  } {\n    return {\n      graph: this.graph,\n      weights: Object.fromEntries(this.weights),\n      biases: Object.fromEntries(this.biases),\n      trainingState: this.trainingState,\n      config: this.trainingConfig,\n    };\n  }\n\n  /**\n   * Import model state from persistence\n   */\n  public importModel(modelData: {\n    graph: DomainGraph;\n    weights: Record<string, number[]>;\n    biases: Record<string, number[]>;\n    trainingState: TrainingState;\n    config: TrainingConfig;\n  }): void {\n    this.graph = modelData.graph;\n    this.weights = new Map(Object.entries(modelData.weights));\n    this.biases = new Map(Object.entries(modelData.biases));\n    this.trainingState = modelData.trainingState;\n    this.trainingConfig = { ...this.trainingConfig, ...modelData.config };\n    \n    this.emit('model-imported', modelData);\n  }\n\n  // Stub implementations for remaining methods\n  private generateCohesionSuggestions(domainId: string, factors: any): string[] {\n    return ['Improve structural cohesion', 'Enhance functional alignment'];\n  }\n\n  private identifyWeaknessReason(structural: number, functional: number, behavioral: number, semantic: number): string {\n    const lowest = Math.min(structural, functional, behavioral, semantic);\n    if (lowest === structural) return 'Poor structural cohesion';\n    if (lowest === functional) return 'Low functional alignment';\n    if (lowest === behavioral) return 'Inconsistent behavior patterns';\n    return 'Weak semantic relationships';\n  }\n\n  private async generateCohesionRecommendations(domainScores: Map<string, number>, weakPoints: any[]): Promise<CohesionAnalysis['recommendations']> {\n    return [\n      {\n        type: 'restructure',\n        target: ['domain1', 'domain2'],\n        impact: 0.3,\n        confidence: 0.8,\n      },\n    ];\n  }\n\n  private async generateDependencyOptimizations(dependencyGraph: any, circularDependencies: any, criticalPaths: any): Promise<DependencyAnalysis['optimizations']> {\n    return [\n      {\n        type: 'break-cycle',\n        affected: ['domain1', 'domain2'],\n        benefit: 0.5,\n        effort: 0.3,\n      },\n    ];\n  }\n\n  private async generateMergeProposals(proposals: any[], cohesionAnalysis: any, dependencyAnalysis: any): Promise<void> {\n    // Implementation would analyze highly coupled domains for merge opportunities\n  }\n\n  private async generateSplitProposals(proposals: any[], cohesionAnalysis: any, dependencyAnalysis: any): Promise<void> {\n    // Implementation would identify large, low-cohesion domains for splitting\n  }\n\n  private async generateRelocationProposals(proposals: any[], cohesionAnalysis: any, dependencyAnalysis: any): Promise<void> {\n    // Implementation would suggest moving functionality between domains\n  }\n\n  private async generateAbstractionProposals(proposals: any[], cohesionAnalysis: any, dependencyAnalysis: any): Promise<void> {\n    // Implementation would identify common patterns for abstraction\n  }\n\n  private calculateOptimizationScore(proposals: any[]): number {\n    return proposals.reduce((score, p) => score + p.confidence * 0.1, 0);\n  }\n\n  private determinePriority(cohesionAnalysis: any, dependencyAnalysis: any, optimizationScore: number): 'low' | 'medium' | 'high' | 'critical' {\n    if (cohesionAnalysis.overallScore < 0.3) return 'critical';\n    if (optimizationScore > 0.7) return 'high';\n    if (optimizationScore > 0.4) return 'medium';\n    return 'low';\n  }\n\n  private generateHighLevelRecommendations(cohesion: any, dependencies: any, optimization: any): string[] {\n    const recommendations = [];\n    \n    if (cohesion.overallScore < 0.6) {\n      recommendations.push('Consider domain restructuring to improve cohesion');\n    }\n    \n    if (dependencies.circularDependencies.length > 0) {\n      recommendations.push('Address circular dependencies to improve maintainability');\n    }\n    \n    if (optimization.priority === 'high' || optimization.priority === 'critical') {\n      recommendations.push('Implement boundary optimizations to improve system architecture');\n    }\n    \n    return recommendations;\n  }\n}\n\n// ===== Export Types =====\n\nexport type {\n  DomainNode,\n  DomainEdge,\n  DomainGraph,\n  CohesionAnalysis,\n  DependencyAnalysis,\n  BoundaryOptimization,\n  GNNLayerConfig,\n  TrainingConfig,\n};"],"names":["EventEmitter","NeuralDomainMapper","graph","layers","trainingConfig","trainingState","patternStore","isTraining","modelVersion","weights","Map","biases","config","learningRate","batchSize","epochs","optimizer","lossFunction","regularization","l1","l2","dropout","earlyStoping","enabled","patience","minDelta","validationSplit","nodes","edges","metadata","created","Date","now","lastTraining","version","cohesionScore","totalNodes","totalEdges","type","inputDim","outputDim","activation","normalization","numHeads","epoch","loss","Infinity","accuracy","checkpoints","createDefaultPatternStore","initializeWeights","convertToGraph","domains","relationships","clear","domain","node","id","name","features","extractDomainFeatures","size","complexity","stability","dependencies","lastUpdated","embedding","initializeNodeEmbedding","set","rel","edgeId","source","target","edge","weight","extractEdgeFeatures","frequency","latency","reliability","bandwidth","direction","emit","types","typeEncoding","map","t","push","length","Math","min","slice","relationship","calculateDomainCohesion","domainScores","weakPoints","totalStructural","totalFunctional","totalBehavioral","totalSemantic","domainId","structural","calculateStructuralCohesion","functional","calculateFunctionalCohesion","behavioral","calculateBehavioralCohesion","semantic","calculateSemanticCohesion","domainScore","suggestions","generateCohesionSuggestions","score","reason","identifyWeaknessReason","nodeCount","overallScore","Array","from","values","reduce","sum","analysis","factors","recommendations","generateCohesionRecommendations","get","outgoingEdges","filter","e","incomingEdges","maxPossibleEdges","connectivity","weightedConnectivity","connectedDomains","getConnectedDomains","sameTypePenalty","d","avgComplexity","complexityAlignment","abs","relatedEdges","avgFrequency","avgReliability","avgLatency","frequencyScore","reliabilityScore","latencyScore","max","semanticScore","connectedDomain","nameSimilarity","calculateNameSimilarity","typeSimilarity","connectedIds","Set","add","Boolean","name1","name2","words1","toLowerCase","split","words2","commonWords","w","includes","totalWords","identifyCrossDomainDependencies","dependencyGraph","circularDependencies","criticalPaths","nodeId","visited","recursionStack","detectCircularDFS","path","depId","has","cycleStart","indexOf","cycle","delete","calculateRisk","totalRisk","i","criticality","calculateImpact","affectedDomains","deps","findLongestPaths","risk","impact","inDegrees","outDegrees","averageInDegree","deg","averageOutDegree","calculateMaxDepth","depths","keys","maxDepth","cyclomaticComplexity","sort","a","b","metrics","optimizations","generateDependencyOptimizations","provideBoundaryOptimization","proposals","cohesionAnalysis","dependencyAnalysis","generateMergeProposals","generateSplitProposals","generateRelocationProposals","generateAbstractionProposals","optimizationScore","calculateOptimizationScore","priority","determinePriority","optimization","confidence","train","trainingData","validationData","Error","trainingHistory","bestAccuracy","bestWeights","bestBiases","patienceCounter","trainEpoch","validationLoss","validationAccuracy","validationResults","validateModel","epochResult","currentAccuracy","console","log","result","finalAccuracy","bestModel","totalLoss","correct","total","indices","inputs","_","shuffleArray","batchIndices","batchInputs","idx","batchTargets","outputs","processBatch","ceil","targets","predictions","input","forwardPass","calculateLoss","calculateAccuracy","backwardPass","preprocessInput","layerConfig","processLayer","outputGradients","calculateOutputGradients","gradients","weightGradients","biasGradients","inputGradients","calculateLayerGradients","updateWeights","updateBiases","predict","output","calculatePredictionConfidence","alternatives","generateAlternativePredictions","prediction","analyzeDomains","cohesion","Promise","all","generateHighLevelRecommendations","patterns","pattern","findSimilar","threshold","p","calculatePatternSimilarity","getByType","prune","maxAge","cutoff","export","import","importedPatterns","random","layer","limit","sqrt","array","j","floor","fill","weightIndex","applyActivation","x","tanh","exp","PI","pow","pred","isArray","diff","sampleCorrect","sampleGradients","targetVal","sampleInputGradients","grad","layerId","lr","maxVal","minVal","range","count","noisyInput","addNoiseToInput","noiseLevel","noisyFeatures","f","p1","p2","similarity","undefined","getModelStats","graphSize","exportModel","Object","fromEntries","importModel","modelData","entries","lowest","affected","benefit","effort"],"mappings":"AA0BA,SAASA,YAAY,QAAQ,SAAS;AAoOtC,OAAO,MAAMC,2BAA2BD;IAC9BE,MAAmB;IACnBC,OAAyB;IACzBC,eAA+B;IAC/BC,cAA6B;IAC7BC,aAA2B;IAC3BC,aAAsB,MAAM;IAC5BC,eAAuB,QAAQ;IAC/BC,UAAiC,IAAIC,MAAM;IAC3CC,SAAgC,IAAID,MAAM;IAQlD,YACEE,SAAkC,CAAC,CAAC,EACpCN,YAA2B,CAC3B;QACA,KAAK;QAEL,IAAI,CAACF,cAAc,GAAG;YACpBS,cAAc;YACdC,WAAW;YACXC,QAAQ;YACRC,WAAW;YACXC,cAAc;YACdC,gBAAgB;gBACdC,IAAI;gBACJC,IAAI;gBACJC,SAAS;YACX;YACAC,cAAc;gBACZC,SAAS;gBACTC,UAAU;gBACVC,UAAU;YACZ;YACAC,iBAAiB;YACjB,GAAGd,MAAM;QACX;QAEA,IAAI,CAACV,KAAK,GAAG;YACXyB,OAAO,IAAIjB;YACXkB,OAAO,IAAIlB;YACXmB,UAAU;gBACRC,SAASC,KAAKC,GAAG;gBACjBC,cAAc;gBACdC,SAAS,IAAI,CAAC1B,YAAY;gBAC1B2B,eAAe;gBACfC,YAAY;gBACZC,YAAY;YACd;QACF;QAEA,IAAI,CAAClC,MAAM,GAAG;YACZ;gBACEmC,MAAM;gBACNC,UAAU;gBACVC,WAAW;gBACXnB,SAAS;gBACToB,YAAY;gBACZC,eAAe;YACjB;YACA;gBACEJ,MAAM;gBACNC,UAAU;gBACVC,WAAW;gBACXG,UAAU;gBACVtB,SAAS;gBACToB,YAAY;gBACZC,eAAe;YACjB;YACA;gBACEJ,MAAM;gBACNC,UAAU;gBACVC,WAAW;gBACXnB,SAAS;gBACToB,YAAY;YACd;SACD;QAED,IAAI,CAACpC,aAAa,GAAG;YACnBuC,OAAO;YACPC,MAAMC;YACNC,UAAU;YACVlC,cAAc,IAAI,CAACT,cAAc,CAACS,YAAY;YAC9CG,WAAW,IAAI,CAACZ,cAAc,CAACY,SAAS;YACxCgC,aAAa,EAAE;QACjB;QAEA,IAAI,CAAC1C,YAAY,GAAGA,gBAAgB,IAAI,CAAC2C,yBAAyB;QAClE,IAAI,CAACC,iBAAiB;IACxB;IAWOC,eACLC,OAKE,EACFC,aAME,EACW;QAEb,IAAI,CAACnD,KAAK,CAACyB,KAAK,CAAC2B,KAAK;QACtB,IAAI,CAACpD,KAAK,CAAC0B,KAAK,CAAC0B,KAAK;QAGtB,KAAK,MAAMC,UAAUH,QAAS;YAC5B,MAAMI,OAAmB;gBACvBC,IAAIF,OAAOE,EAAE;gBACbC,MAAMH,OAAOG,IAAI;gBACjBpB,MAAMiB,OAAOjB,IAAI;gBACjBqB,UAAU,IAAI,CAACC,qBAAqB,CAACL;gBACrC1B,UAAU;oBACRgC,MAAMN,OAAO1B,QAAQ,EAAEgC,QAAQ;oBAC/BC,YAAYP,OAAO1B,QAAQ,EAAEiC,cAAc;oBAC3CC,WAAWR,OAAO1B,QAAQ,EAAEkC,aAAa;oBACzCC,cAAcT,OAAO1B,QAAQ,EAAEmC,gBAAgB,EAAE;oBACjDC,aAAaV,OAAO1B,QAAQ,EAAEoC,eAAelC,KAAKC,GAAG;oBACrDE,SAASqB,OAAO1B,QAAQ,EAAEK,WAAW;gBACvC;gBACAO,YAAY;gBACZyB,WAAW,IAAI,CAACC,uBAAuB,CAACZ,OAAOE,EAAE;YACnD;YAEA,IAAI,CAACvD,KAAK,CAACyB,KAAK,CAACyC,GAAG,CAACb,OAAOE,EAAE,EAAED;QAClC;QAGA,KAAK,MAAMa,OAAOhB,cAAe;YAC/B,MAAMiB,SAAS,GAAGD,IAAIE,MAAM,CAAC,EAAE,EAAEF,IAAIG,MAAM,EAAE;YAC7C,MAAMC,OAAmB;gBACvBF,QAAQF,IAAIE,MAAM;gBAClBC,QAAQH,IAAIG,MAAM;gBAClBE,QAAQL,IAAIK,MAAM,IAAI;gBACtBpC,MAAM+B,IAAI/B,IAAI;gBACdqB,UAAU,IAAI,CAACgB,mBAAmB,CAACN;gBACnCxC,UAAU;oBACR+C,WAAWP,IAAIxC,QAAQ,EAAE+C,aAAa;oBACtCC,SAASR,IAAIxC,QAAQ,EAAEgD,WAAW;oBAClCC,aAAaT,IAAIxC,QAAQ,EAAEiD,eAAe;oBAC1CC,WAAWV,IAAIxC,QAAQ,EAAEkD,aAAa;oBACtCC,WAAWX,IAAIxC,QAAQ,EAAEmD,aAAa;gBACxC;YACF;YAEA,IAAI,CAAC9E,KAAK,CAAC0B,KAAK,CAACwC,GAAG,CAACE,QAAQG;QAC/B;QAGA,IAAI,CAACvE,KAAK,CAAC2B,QAAQ,CAACO,UAAU,GAAG,IAAI,CAAClC,KAAK,CAACyB,KAAK,CAACkC,IAAI;QACtD,IAAI,CAAC3D,KAAK,CAAC2B,QAAQ,CAACQ,UAAU,GAAG,IAAI,CAACnC,KAAK,CAAC0B,KAAK,CAACiC,IAAI;QACtD,IAAI,CAAC3D,KAAK,CAAC2B,QAAQ,CAACI,YAAY,GAAG;QAEnC,IAAI,CAACgD,IAAI,CAAC,iBAAiB,IAAI,CAAC/E,KAAK;QACrC,OAAO,IAAI,CAACA,KAAK;IACnB;IAKQ0D,sBAAsBL,MAAW,EAAY;QACnD,MAAMI,WAAqB,EAAE;QAG7B,MAAMuB,QAAQ;YAAC;YAAc;YAAa;YAAY;YAAe;YAAQ;YAAM;SAAM;QACzF,MAAMC,eAAeD,MAAME,GAAG,CAACC,CAAAA,IAAKA,MAAM9B,OAAOjB,IAAI,GAAG,IAAI;QAC5DqB,SAAS2B,IAAI,IAAIH;QAGjBxB,SAAS2B,IAAI,CACX/B,OAAO1B,QAAQ,EAAEgC,QAAQ,GACzBN,OAAO1B,QAAQ,EAAEiC,cAAc,KAC/BP,OAAO1B,QAAQ,EAAEkC,aAAa,KAC9B,AAACR,CAAAA,OAAO1B,QAAQ,EAAEmC,cAAcuB,UAAU,CAAA,IAAK,IAC/CC,KAAKC,GAAG,CAAC,AAAC1D,CAAAA,KAAKC,GAAG,KAAMuB,CAAAA,OAAO1B,QAAQ,EAAEoC,eAAelC,KAAKC,GAAG,EAAC,CAAC,IAAM,CAAA,OAAO,KAAK,KAAK,EAAC,GAAI;QAIhG,MAAO2B,SAAS4B,MAAM,GAAG,GAAI;YAC3B5B,SAAS2B,IAAI,CAAC;QAChB;QAEA,OAAO3B,SAAS+B,KAAK,CAAC,GAAG;IAC3B;IAKQf,oBAAoBgB,YAAiB,EAAY;QACvD,MAAMhC,WAAqB,EAAE;QAG7B,MAAMuB,QAAQ;YAAC;YAAc;YAAiB;YAAa;YAAe;YAAe;SAAc;QACvG,MAAMC,eAAeD,MAAME,GAAG,CAACC,CAAAA,IAAKA,MAAMM,aAAarD,IAAI,GAAG,IAAI;QAClEqB,SAAS2B,IAAI,IAAIH;QAGjBxB,SAAS2B,IAAI,CACXK,aAAa9D,QAAQ,EAAE+C,aAAa,GACpCe,aAAa9D,QAAQ,EAAEgD,WAAW,KAClCc,aAAa9D,QAAQ,EAAEiD,eAAe,MACtCa,aAAa9D,QAAQ,EAAEkD,aAAa,MACpCY,aAAa9D,QAAQ,EAAEmD,cAAc,kBAAkB,IAAI;QAI7D,MAAOrB,SAAS4B,MAAM,GAAG,GAAI;YAC3B5B,SAAS2B,IAAI,CAAC;QAChB;QAEA,OAAO3B,SAAS+B,KAAK,CAAC,GAAG;IAC3B;IASA,MAAaE,0BAAqD;QAChE,MAAMC,eAAe,IAAInF;QACzB,MAAMoF,aAKD,EAAE;QAEP,IAAIC,kBAAkB;QACtB,IAAIC,kBAAkB;QACtB,IAAIC,kBAAkB;QACtB,IAAIC,gBAAgB;QAGpB,KAAK,MAAM,CAACC,UAAU3C,KAAK,IAAI,IAAI,CAACtD,KAAK,CAACyB,KAAK,CAAE;YAC/C,MAAMyE,aAAa,IAAI,CAACC,2BAA2B,CAACF;YACpD,MAAMG,aAAa,IAAI,CAACC,2BAA2B,CAACJ;YACpD,MAAMK,aAAa,IAAI,CAACC,2BAA2B,CAACN;YACpD,MAAMO,WAAW,IAAI,CAACC,yBAAyB,CAACR;YAEhD,MAAMS,cAAc,AAACR,CAAAA,aAAaE,aAAaE,aAAaE,QAAO,IAAK;YACxEb,aAAazB,GAAG,CAAC+B,UAAUS;YAE3Bb,mBAAmBK;YACnBJ,mBAAmBM;YACnBL,mBAAmBO;YACnBN,iBAAiBQ;YAGjB,IAAIE,cAAc,KAAK;gBACrB,MAAMC,cAAc,IAAI,CAACC,2BAA2B,CAACX,UAAU;oBAC7DC;oBACAE;oBACAE;oBACAE;gBACF;gBAEAZ,WAAWR,IAAI,CAAC;oBACda;oBACAY,OAAOH;oBACPI,QAAQ,IAAI,CAACC,sBAAsB,CAACb,YAAYE,YAAYE,YAAYE;oBACxEG;gBACF;YACF;QACF;QAEA,MAAMK,YAAY,IAAI,CAAChH,KAAK,CAACyB,KAAK,CAACkC,IAAI;QACvC,MAAMsD,eAAeC,MAAMC,IAAI,CAACxB,aAAayB,MAAM,IAAIC,MAAM,CAAC,CAACC,KAAKT,QAAUS,MAAMT,OAAO,KAAKG;QAEhG,MAAMO,WAA6B;YACjCN;YACAtB;YACA6B,SAAS;gBACPtB,YAAYL,kBAAkBmB;gBAC9BZ,YAAYN,kBAAkBkB;gBAC9BV,YAAYP,kBAAkBiB;gBAC9BR,UAAUR,gBAAgBgB;YAC5B;YACApB;YACA6B,iBAAiB,MAAM,IAAI,CAACC,+BAA+B,CAAC/B,cAAcC;QAC5E;QAGA,IAAI,CAAC5F,KAAK,CAAC2B,QAAQ,CAACM,aAAa,GAAGgF;QAEpC,IAAI,CAAClC,IAAI,CAAC,uBAAuBwC;QACjC,OAAOA;IACT;IAKQpB,4BAA4BF,QAAgB,EAAU;QAC5D,MAAM3C,OAAO,IAAI,CAACtD,KAAK,CAACyB,KAAK,CAACkG,GAAG,CAAC1B;QAClC,IAAI,CAAC3C,MAAM,OAAO;QAElB,MAAMsE,gBAAgBV,MAAMC,IAAI,CAAC,IAAI,CAACnH,KAAK,CAAC0B,KAAK,CAAC0F,MAAM,IAAIS,MAAM,CAACC,CAAAA,IAAKA,EAAEzD,MAAM,KAAK4B;QACrF,MAAM8B,gBAAgBb,MAAMC,IAAI,CAAC,IAAI,CAACnH,KAAK,CAAC0B,KAAK,CAAC0F,MAAM,IAAIS,MAAM,CAACC,CAAAA,IAAKA,EAAExD,MAAM,KAAK2B;QAErF,MAAM9D,aAAayF,cAAcvC,MAAM,GAAG0C,cAAc1C,MAAM;QAC9D,MAAM2C,mBAAmB,AAAC,CAAA,IAAI,CAAChI,KAAK,CAACyB,KAAK,CAACkC,IAAI,GAAG,CAAA,IAAK;QAEvD,MAAMsE,eAAe9F,aAAa6F;QAGlC,MAAME,uBAAuB,AAC3BN,CAAAA,cAAcP,MAAM,CAAC,CAACC,KAAKQ,IAAMR,MAAMQ,EAAEtD,MAAM,EAAE,KACjDuD,cAAcV,MAAM,CAAC,CAACC,KAAKQ,IAAMR,MAAMQ,EAAEtD,MAAM,EAAE,EAAC,IAC/CrC,CAAAA,cAAc,CAAA;QAEnB,OAAOmD,KAAKC,GAAG,CAAC,AAAC0C,CAAAA,eAAeC,oBAAmB,IAAK,GAAG;IAC7D;IAKQ7B,4BAA4BJ,QAAgB,EAAU;QAC5D,MAAM3C,OAAO,IAAI,CAACtD,KAAK,CAACyB,KAAK,CAACkG,GAAG,CAAC1B;QAClC,IAAI,CAAC3C,MAAM,OAAO;QAGlB,MAAM6E,mBAAmB,IAAI,CAACC,mBAAmB,CAACnC;QAClD,MAAMoC,kBAAkBF,iBAAiBN,MAAM,CAACS,CAAAA,IAAKA,EAAElG,IAAI,KAAKkB,KAAKlB,IAAI,EAAEiD,MAAM,GAAI8C,CAAAA,iBAAiB9C,MAAM,IAAI,CAAA;QAGhH,MAAMkD,gBAAgBJ,iBAAiBd,MAAM,CAAC,CAACC,KAAKgB,IAAMhB,MAAMgB,EAAE3G,QAAQ,CAACiC,UAAU,EAAE,KAAMuE,CAAAA,iBAAiB9C,MAAM,IAAI,CAAA;QACxH,MAAMmD,sBAAsB,IAAIlD,KAAKmD,GAAG,CAACnF,KAAK3B,QAAQ,CAACiC,UAAU,GAAG2E;QAEpE,OAAQF,kBAAkB,MAAMG,sBAAsB;IACxD;IAKQjC,4BAA4BN,QAAgB,EAAU;QAC5D,MAAMyC,eAAexB,MAAMC,IAAI,CAAC,IAAI,CAACnH,KAAK,CAAC0B,KAAK,CAAC0F,MAAM,IAAIS,MAAM,CAC/DC,CAAAA,IAAKA,EAAEzD,MAAM,KAAK4B,YAAY6B,EAAExD,MAAM,KAAK2B;QAG7C,IAAIyC,aAAarD,MAAM,KAAK,GAAG,OAAO;QAGtC,MAAMsD,eAAeD,aAAarB,MAAM,CAAC,CAACC,KAAKQ,IAAMR,MAAMQ,EAAEnG,QAAQ,CAAC+C,SAAS,EAAE,KAAKgE,aAAarD,MAAM;QACzG,MAAMuD,iBAAiBF,aAAarB,MAAM,CAAC,CAACC,KAAKQ,IAAMR,MAAMQ,EAAEnG,QAAQ,CAACiD,WAAW,EAAE,KAAK8D,aAAarD,MAAM;QAC7G,MAAMwD,aAAaH,aAAarB,MAAM,CAAC,CAACC,KAAKQ,IAAMR,MAAMQ,EAAEnG,QAAQ,CAACgD,OAAO,EAAE,KAAK+D,aAAarD,MAAM;QAGrG,MAAMyD,iBAAiBxD,KAAKC,GAAG,CAACoD,eAAe,IAAI;QACnD,MAAMI,mBAAmBH;QACzB,MAAMI,eAAe1D,KAAK2D,GAAG,CAAC,GAAG,IAAIJ,aAAa;QAElD,OAAO,AAACC,CAAAA,iBAAiBC,mBAAmBC,YAAW,IAAK;IAC9D;IAKQvC,0BAA0BR,QAAgB,EAAU;QAC1D,MAAM3C,OAAO,IAAI,CAACtD,KAAK,CAACyB,KAAK,CAACkG,GAAG,CAAC1B;QAClC,IAAI,CAAC3C,MAAM,OAAO;QAElB,MAAM6E,mBAAmB,IAAI,CAACC,mBAAmB,CAACnC;QAGlD,IAAIiD,gBAAgB;QACpB,KAAK,MAAMC,mBAAmBhB,iBAAkB;YAC9C,MAAMiB,iBAAiB,IAAI,CAACC,uBAAuB,CAAC/F,KAAKE,IAAI,EAAE2F,gBAAgB3F,IAAI;YACnF,MAAM8F,iBAAiBhG,KAAKlB,IAAI,KAAK+G,gBAAgB/G,IAAI,GAAG,IAAI;YAChE8G,iBAAiB,AAACE,CAAAA,iBAAiBE,cAAa,IAAK;QACvD;QAEA,OAAOnB,iBAAiB9C,MAAM,GAAG,IAAI6D,gBAAgBf,iBAAiB9C,MAAM,GAAG;IACjF;IAKQ+C,oBAAoBnC,QAAgB,EAAgB;QAC1D,MAAMsD,eAAe,IAAIC;QAEzB,KAAK,MAAMjF,QAAQ,IAAI,CAACvE,KAAK,CAAC0B,KAAK,CAAC0F,MAAM,GAAI;YAC5C,IAAI7C,KAAKF,MAAM,KAAK4B,UAAU;gBAC5BsD,aAAaE,GAAG,CAAClF,KAAKD,MAAM;YAC9B,OAAO,IAAIC,KAAKD,MAAM,KAAK2B,UAAU;gBACnCsD,aAAaE,GAAG,CAAClF,KAAKF,MAAM;YAC9B;QACF;QAEA,OAAO6C,MAAMC,IAAI,CAACoC,cACfrE,GAAG,CAAC3B,CAAAA,KAAM,IAAI,CAACvD,KAAK,CAACyB,KAAK,CAACkG,GAAG,CAACpE,KAC/BsE,MAAM,CAAC6B;IACZ;IAKQL,wBAAwBM,KAAa,EAAEC,KAAa,EAAU;QACpE,MAAMC,SAASF,MAAMG,WAAW,GAAGC,KAAK,CAAC;QACzC,MAAMC,SAASJ,MAAME,WAAW,GAAGC,KAAK,CAAC;QAEzC,MAAME,cAAcJ,OAAOhC,MAAM,CAACqC,CAAAA,IAAKF,OAAOG,QAAQ,CAACD;QACvD,MAAME,aAAa,IAAIZ,IAAI;eAAIK;eAAWG;SAAO,EAAErG,IAAI;QAEvD,OAAOyG,aAAa,IAAIH,YAAY5E,MAAM,GAAG+E,aAAa;IAC5D;IASA,MAAaC,kCAA+D;QAC1E,MAAMC,kBAAkB,IAAI9J;QAC5B,MAAM+J,uBAAmC,EAAE;QAC3C,MAAMC,gBAID,EAAE;QAGP,KAAK,MAAM,CAACC,QAAO,IAAI,IAAI,CAACzK,KAAK,CAACyB,KAAK,CAAE;YACvC,MAAMqC,eAAyB,EAAE;YAEjC,KAAK,MAAMS,QAAQ,IAAI,CAACvE,KAAK,CAAC0B,KAAK,CAAC0F,MAAM,GAAI;gBAC5C,IAAI7C,KAAKF,MAAM,KAAKoG,WAAUlG,KAAKnC,IAAI,KAAK,cAAc;oBACxD0B,aAAasB,IAAI,CAACb,KAAKD,MAAM;gBAC/B;YACF;YAEAgG,gBAAgBpG,GAAG,CAACuG,SAAQ3G;QAC9B;QAGA,MAAM4G,UAAU,IAAIlB;QACpB,MAAMmB,iBAAiB,IAAInB;QAE3B,MAAMoB,oBAAoB,CAACH,SAAgBI;YACzCH,QAAQjB,GAAG,CAACgB;YACZE,eAAelB,GAAG,CAACgB;YACnBI,KAAKzF,IAAI,CAACqF;YAEV,MAAM3G,eAAewG,gBAAgB3C,GAAG,CAAC8C,YAAW,EAAE;YACtD,KAAK,MAAMK,SAAShH,aAAc;gBAChC,IAAI,CAAC4G,QAAQK,GAAG,CAACD,QAAQ;oBACvBF,kBAAkBE,OAAO;2BAAID;qBAAK;gBACpC,OAAO,IAAIF,eAAeI,GAAG,CAACD,QAAQ;oBAEpC,MAAME,aAAaH,KAAKI,OAAO,CAACH;oBAChC,MAAMI,QAAQL,KAAKrF,KAAK,CAACwF;oBACzBT,qBAAqBnF,IAAI,CAAC;2BAAI8F;wBAAOJ;qBAAM;gBAC7C;YACF;YAEAH,eAAeQ,MAAM,CAACV;QACxB;QAEA,KAAK,MAAM,CAACA,QAAO,IAAI,IAAI,CAACzK,KAAK,CAACyB,KAAK,CAAE;YACvC,IAAI,CAACiJ,QAAQK,GAAG,CAACN,UAAS;gBACxBG,kBAAkBH,SAAQ,EAAE;YAC9B;QACF;QAGA,MAAMW,gBAAgB,CAACP;YACrB,IAAIQ,YAAY;YAChB,IAAK,IAAIC,IAAI,GAAGA,IAAIT,KAAKxF,MAAM,GAAG,GAAGiG,IAAK;gBACxC,MAAMlH,SAAS,GAAGyG,IAAI,CAACS,EAAE,CAAC,EAAE,EAAET,IAAI,CAACS,IAAI,EAAE,EAAE;gBAC3C,MAAM/G,OAAO,IAAI,CAACvE,KAAK,CAAC0B,KAAK,CAACiG,GAAG,CAACvD;gBAClC,IAAIG,MAAM;oBAER,MAAMK,cAAcL,KAAK5C,QAAQ,CAACiD,WAAW;oBAC7C,MAAM2G,cAAc,IAAI3G;oBACxByG,aAAaE;gBACf;YACF;YACA,OAAOF,YAAaR,CAAAA,KAAKxF,MAAM,GAAG,CAAA;QACpC;QAEA,MAAMmG,kBAAkB,CAACX;YAEvB,MAAMY,kBAAkB,IAAIjC;YAE5B,KAAK,MAAMiB,WAAUI,KAAM;gBAEzB,KAAK,MAAM,CAACC,OAAOY,KAAK,IAAIpB,gBAAiB;oBAC3C,IAAIoB,KAAKvB,QAAQ,CAACM,UAAS;wBACzBgB,gBAAgBhC,GAAG,CAACqB;oBACtB;gBACF;YACF;YAEA,OAAOW,gBAAgB9H,IAAI,GAAG,IAAI,CAAC3D,KAAK,CAACyB,KAAK,CAACkC,IAAI;QACrD;QAGA,MAAMgI,mBAAmB,CAAClB,SAAgBC,SAAsBG;YAC9D,IAAIA,KAAKxF,MAAM,GAAG,GAAG;gBACnB,MAAMuG,OAAOR,cAAcP;gBAC3B,MAAMgB,SAASL,gBAAgBX;gBAE/B,IAAIe,OAAO,OAAOC,SAAS,KAAK;oBAC9BrB,cAAcpF,IAAI,CAAC;wBACjByF,MAAM;+BAAIA;yBAAK;wBACfe;wBACAC;oBACF;gBACF;YACF;YAEA,MAAM/H,eAAewG,gBAAgB3C,GAAG,CAAC8C,YAAW,EAAE;YACtD,KAAK,MAAMK,SAAShH,aAAc;gBAChC,IAAI,CAAC4G,QAAQK,GAAG,CAACD,QAAQ;oBACvBJ,QAAQjB,GAAG,CAACqB;oBACZa,iBAAiBb,OAAOJ,SAAS;2BAAIG;wBAAMC;qBAAM;oBACjDJ,QAAQS,MAAM,CAACL;gBACjB;YACF;QACF;QAEA,KAAK,MAAM,CAACL,QAAO,IAAI,IAAI,CAACzK,KAAK,CAACyB,KAAK,CAAE;YACvC,MAAMiJ,UAAU,IAAIlB,IAAI;gBAACiB;aAAO;YAChCkB,iBAAiBlB,SAAQC,SAAS;gBAACD;aAAO;QAC5C;QAGA,MAAMqB,YAAY,IAAItL;QACtB,MAAMuL,aAAa,IAAIvL;QAEvB,KAAK,MAAM,CAACiK,QAAO,IAAI,IAAI,CAACzK,KAAK,CAACyB,KAAK,CAAE;YACvCqK,UAAU5H,GAAG,CAACuG,SAAQ;YACtBsB,WAAW7H,GAAG,CAACuG,SAAQ;QACzB;QAEA,KAAK,MAAMiB,QAAQpB,gBAAgBlD,MAAM,GAAI;YAC3C2E,WAAW7H,GAAG,CAACuG,QAAQiB,KAAKrG,MAAM;YAClC,KAAK,MAAMyF,SAASY,KAAM;gBACxBI,UAAU5H,GAAG,CAAC4G,OAAO,AAACgB,CAAAA,UAAUnE,GAAG,CAACmD,UAAU,CAAA,IAAK;YACrD;QACF;QAEA,MAAMkB,kBAAkB9E,MAAMC,IAAI,CAAC2E,UAAU1E,MAAM,IAAIC,MAAM,CAAC,CAACC,KAAK2E,MAAQ3E,MAAM2E,KAAK,KAAK,IAAI,CAACjM,KAAK,CAACyB,KAAK,CAACkC,IAAI;QACjH,MAAMuI,mBAAmBhF,MAAMC,IAAI,CAAC4E,WAAW3E,MAAM,IAAIC,MAAM,CAAC,CAACC,KAAK2E,MAAQ3E,MAAM2E,KAAK,KAAK,IAAI,CAACjM,KAAK,CAACyB,KAAK,CAACkC,IAAI;QAGnH,MAAMwI,oBAAoB,CAAC1B,SAAgBC;YACzC,IAAIA,QAAQK,GAAG,CAACN,UAAS,OAAO;YAChCC,QAAQjB,GAAG,CAACgB;YAEZ,MAAM3G,eAAewG,gBAAgB3C,GAAG,CAAC8C,YAAW,EAAE;YACtD,IAAI3G,aAAauB,MAAM,KAAK,GAAG,OAAO;YAEtC,MAAM+G,SAAStI,aAAaoB,GAAG,CAAC4F,CAAAA,QAASqB,kBAAkBrB,OAAO,IAAItB,IAAIkB;YAC1E,OAAO,IAAIpF,KAAK2D,GAAG,IAAImD,QAAQ;QACjC;QAEA,MAAMA,SAASlF,MAAMC,IAAI,CAAC,IAAI,CAACnH,KAAK,CAACyB,KAAK,CAAC4K,IAAI,IAAInH,GAAG,CAACuF,CAAAA,UAAU0B,kBAAkB1B,SAAQ,IAAIjB;QAC/F,MAAM8C,WAAWhH,KAAK2D,GAAG,IAAImD,QAAQ;QAGrC,MAAMG,uBAAuB,IAAI,CAACvM,KAAK,CAAC0B,KAAK,CAACiC,IAAI,GAAG,IAAI,CAAC3D,KAAK,CAACyB,KAAK,CAACkC,IAAI,GAAG;QAE7E,MAAM4D,WAA+B;YACnCvH,OAAOsK;YACPC;YACAC,eAAeA,cAAcgC,IAAI,CAAC,CAACC,GAAGC,IAAM,AAACA,EAAEd,IAAI,GAAGc,EAAEb,MAAM,GAAKY,CAAAA,EAAEb,IAAI,GAAGa,EAAEZ,MAAM,AAAD,GAAIrG,KAAK,CAAC,GAAG;YAChGmH,SAAS;gBACPX;gBACAE;gBACAI;gBACAC;YACF;YACAK,eAAe,MAAM,IAAI,CAACC,+BAA+B,CACvDvC,iBACAC,sBACAC;QAEJ;QAEA,IAAI,CAACzF,IAAI,CAAC,yBAAyBwC;QACnC,OAAOA;IACT;IASA,MAAauF,8BAA6D;QACxE,MAAMC,YAA+C,EAAE;QAGvD,MAAMC,mBAAmB,MAAM,IAAI,CAACtH,uBAAuB;QAC3D,MAAMuH,qBAAqB,MAAM,IAAI,CAAC5C,+BAA+B;QAGrE,MAAM,IAAI,CAAC6C,sBAAsB,CAACH,WAAWC,kBAAkBC;QAG/D,MAAM,IAAI,CAACE,sBAAsB,CAACJ,WAAWC,kBAAkBC;QAG/D,MAAM,IAAI,CAACG,2BAA2B,CAACL,WAAWC,kBAAkBC;QAGpE,MAAM,IAAI,CAACI,4BAA4B,CAACN,WAAWC,kBAAkBC;QAGrE,MAAMK,oBAAoB,IAAI,CAACC,0BAA0B,CAACR;QAG1D,MAAMS,WAAW,IAAI,CAACC,iBAAiB,CAACT,kBAAkBC,oBAAoBK;QAE9E,MAAMI,eAAqC;YACzCX,WAAWA,UAAUP,IAAI,CAAC,CAACC,GAAGC,IAAMA,EAAEiB,UAAU,GAAGlB,EAAEkB,UAAU,EAAEnI,KAAK,CAAC,GAAG;YAC1E8H;YACAE;QACF;QAEA,IAAI,CAACzI,IAAI,CAAC,0BAA0B2I;QACpC,OAAOA;IACT;IAWA,MAAaE,MACXC,YAA0B,EAC1BC,cAA6B,EAc5B;QACD,IAAI,IAAI,CAACzN,UAAU,EAAE;YACnB,MAAM,IAAI0N,MAAM;QAClB;QAEA,IAAI,CAAC1N,UAAU,GAAG;QAClB,IAAI,CAAC0E,IAAI,CAAC,oBAAoB;YAAE8I;YAAcC;QAAe;QAE7D,IAAI;YACF,MAAME,kBAMD,EAAE;YAEP,IAAIC,eAAe;YACnB,IAAIC,cAAc,IAAI1N,IAAI,IAAI,CAACD,OAAO;YACtC,IAAI4N,aAAa,IAAI3N,IAAI,IAAI,CAACC,MAAM;YACpC,IAAI2N,kBAAkB;YAGtB,IAAK,IAAI1L,QAAQ,GAAGA,QAAQ,IAAI,CAACxC,cAAc,CAACW,MAAM,EAAE6B,QAAS;gBAC/D,IAAI,CAACvC,aAAa,CAACuC,KAAK,GAAGA;gBAG3B,MAAM,EAAEC,IAAI,EAAEE,QAAQ,EAAE,GAAG,MAAM,IAAI,CAACwL,UAAU,CAACR;gBAGjD,IAAIS;gBACJ,IAAIC;gBAEJ,IAAIT,gBAAgB;oBAClB,MAAMU,oBAAoB,MAAM,IAAI,CAACC,aAAa,CAACX;oBACnDQ,iBAAiBE,kBAAkB7L,IAAI;oBACvC4L,qBAAqBC,kBAAkB3L,QAAQ;gBACjD;gBAGA,IAAI,CAAC1C,aAAa,CAACwC,IAAI,GAAGA;gBAC1B,IAAI,CAACxC,aAAa,CAAC0C,QAAQ,GAAGA;gBAC9B,IAAI,CAAC1C,aAAa,CAACmO,cAAc,GAAGA;gBACpC,IAAI,CAACnO,aAAa,CAACoO,kBAAkB,GAAGA;gBAExC,MAAMG,cAAc;oBAClBhM;oBACAC;oBACAE;oBACAyL;oBACAC;gBACF;gBACAP,gBAAgB5I,IAAI,CAACsJ;gBAGrB,MAAMC,kBAAkBJ,sBAAsB1L;gBAC9C,IAAI8L,kBAAkBV,eAAe,IAAI,CAAC/N,cAAc,CAACkB,YAAY,CAACG,QAAQ,EAAE;oBAC9E0M,eAAeU;oBACfT,cAAc,IAAI1N,IAAI,IAAI,CAACD,OAAO;oBAClC4N,aAAa,IAAI3N,IAAI,IAAI,CAACC,MAAM;oBAChC2N,kBAAkB;gBACpB,OAAO;oBACLA;gBACF;gBAGA,IACE,IAAI,CAAClO,cAAc,CAACkB,YAAY,CAACC,OAAO,IACxC+M,mBAAmB,IAAI,CAAClO,cAAc,CAACkB,YAAY,CAACE,QAAQ,EAC5D;oBACAsN,QAAQC,GAAG,CAAC,CAAC,wBAAwB,EAAEnM,OAAO;oBAC9C;gBACF;gBAGA,IAAIA,QAAQ,KAAKA,QAAQ,OAAO,GAAG;oBACjC,IAAI,CAACxC,cAAc,CAACS,YAAY,IAAI;oBACpC,IAAI,CAACR,aAAa,CAACQ,YAAY,GAAG,IAAI,CAACT,cAAc,CAACS,YAAY;gBACpE;gBAEA,IAAI,CAACoE,IAAI,CAAC,mBAAmB2J;YAC/B;YAGA,IAAI,CAACnO,OAAO,GAAG2N;YACf,IAAI,CAACzN,MAAM,GAAG0N;YAGd,IAAI,CAACnO,KAAK,CAAC2B,QAAQ,CAACI,YAAY,GAAGF,KAAKC,GAAG;YAE3C,MAAMgN,SAAS;gBACbC,eAAed;gBACfD;gBACAgB,WAAW;oBACTzO,SAAS2N;oBACTzN,QAAQ0N;gBACV;YACF;YAEA,IAAI,CAACpJ,IAAI,CAAC,sBAAsB+J;YAChC,OAAOA;QAET,SAAU;YACR,IAAI,CAACzO,UAAU,GAAG;QACpB;IACF;IAKA,MAAcgO,WAAWR,YAA0B,EAGhD;QACD,MAAMjN,YAAY,IAAI,CAACV,cAAc,CAACU,SAAS;QAC/C,IAAIqO,YAAY;QAChB,IAAIC,UAAU;QACd,IAAIC,QAAQ;QAGZ,MAAMC,UAAUlI,MAAMC,IAAI,CAAC;YAAE9B,QAAQwI,aAAawB,MAAM,CAAChK,MAAM;QAAC,GAAG,CAACiK,GAAGhE,IAAMA;QAC7E,IAAI,CAACiE,YAAY,CAACH;QAGlB,IAAK,IAAI9D,IAAI,GAAGA,IAAI8D,QAAQ/J,MAAM,EAAEiG,KAAK1K,UAAW;YAClD,MAAM4O,eAAeJ,QAAQ5J,KAAK,CAAC8F,GAAGA,IAAI1K;YAC1C,MAAM6O,cAAcD,aAAatK,GAAG,CAACwK,CAAAA,MAAO7B,aAAawB,MAAM,CAACK,IAAI;YACpE,MAAMC,eAAeH,aAAatK,GAAG,CAACwK,CAAAA,MAAO7B,aAAa+B,OAAO,CAACF,IAAI;YAEtE,MAAM,EAAE/M,IAAI,EAAEE,QAAQ,EAAE,GAAG,MAAM,IAAI,CAACgN,YAAY,CAACJ,aAAaE;YAEhEV,aAAatM;YACbuM,WAAWrM,WAAW2M,aAAanK,MAAM;YACzC8J,SAASK,aAAanK,MAAM;QAC9B;QAEA,OAAO;YACL1C,MAAMsM,YAAY3J,KAAKwK,IAAI,CAACV,QAAQ/J,MAAM,GAAGzE;YAC7CiC,UAAUqM,UAAUC;QACtB;IACF;IAKA,MAAcU,aACZR,MAAa,EACbU,OAAc,EAC+B;QAE7C,MAAMC,cAAcX,OAAOnK,GAAG,CAAC+K,CAAAA,QAAS,IAAI,CAACC,WAAW,CAACD;QAGzD,MAAMtN,OAAO,IAAI,CAACwN,aAAa,CAACH,aAAaD;QAG7C,MAAMlN,WAAW,IAAI,CAACuN,iBAAiB,CAACJ,aAAaD;QAGrD,MAAM,IAAI,CAACM,YAAY,CAAChB,QAAQW,aAAaD;QAE7C,OAAO;YAAEpN;YAAME;QAAS;IAC1B;IAKQqN,YAAYD,KAAU,EAAY;QACxC,IAAI1N,aAAa,IAAI,CAAC+N,eAAe,CAACL;QAGtC,IAAK,IAAI3E,IAAI,GAAGA,IAAI,IAAI,CAACrL,MAAM,CAACoF,MAAM,EAAEiG,IAAK;YAC3C,MAAMiF,cAAc,IAAI,CAACtQ,MAAM,CAACqL,EAAE;YAClC,MAAM/K,UAAU,IAAI,CAACA,OAAO,CAACoH,GAAG,CAAC,CAAC,MAAM,EAAE2D,GAAG,KAAK,EAAE;YACpD,MAAM7K,SAAS,IAAI,CAACA,MAAM,CAACkH,GAAG,CAAC,CAAC,MAAM,EAAE2D,GAAG,KAAK,EAAE;YAElD/I,aAAa,IAAI,CAACiO,YAAY,CAACjO,YAAYhC,SAASE,QAAQ8P;QAC9D;QAEA,OAAOhO;IACT;IAKA,MAAc8N,aACZhB,MAAa,EACbW,WAAuB,EACvBD,OAAc,EACC;QAEf,MAAMU,kBAAkB,IAAI,CAACC,wBAAwB,CAACV,aAAaD;QAGnE,IAAIY,YAAYF;QAEhB,IAAK,IAAInF,IAAI,IAAI,CAACrL,MAAM,CAACoF,MAAM,GAAG,GAAGiG,KAAK,GAAGA,IAAK;YAChD,MAAMiF,cAAc,IAAI,CAACtQ,MAAM,CAACqL,EAAE;YAClC,MAAM/K,UAAU,IAAI,CAACA,OAAO,CAACoH,GAAG,CAAC,CAAC,MAAM,EAAE2D,GAAG,KAAK,EAAE;YACpD,MAAM7K,SAAS,IAAI,CAACA,MAAM,CAACkH,GAAG,CAAC,CAAC,MAAM,EAAE2D,GAAG,KAAK,EAAE;YAElD,MAAM,EAAEsF,eAAe,EAAEC,aAAa,EAAEC,cAAc,EAAE,GACtD,IAAI,CAACC,uBAAuB,CAACJ,WAAWpQ,SAASE,QAAQ8P;YAG3D,IAAI,CAACS,aAAa,CAAC,CAAC,MAAM,EAAE1F,GAAG,EAAE/K,SAASqQ;YAC1C,IAAI,CAACK,YAAY,CAAC,CAAC,MAAM,EAAE3F,GAAG,EAAE7K,QAAQoQ;YAExCF,YAAYG;QACd;IACF;IAUA,MAAaI,QAAQjB,KAAU,EAAuB;QACpD,IAAI,IAAI,CAAC5P,UAAU,EAAE;YACnB,MAAM,IAAI0N,MAAM;QAClB;QAEA,MAAMoD,SAAS,IAAI,CAACjB,WAAW,CAACD;QAChC,MAAMtC,aAAa,IAAI,CAACyD,6BAA6B,CAACD;QAGtD,MAAME,eAAe,MAAM,IAAI,CAACC,8BAA8B,CAACrB,OAAO;QAEtE,MAAMsB,aAAyB;YAC7BtB;YACAkB;YACAxD;YACA0D;QACF;QAEA,IAAI,CAACtM,IAAI,CAAC,mBAAmBwM;QAC7B,OAAOA;IACT;IAQA,MAAaC,eAAetO,OAAoB,EAK7C;QAED,IAAI,CAAClD,KAAK,GAAG;YAAE,GAAGkD,OAAO;QAAC;QAG1B,MAAM,CAACuO,UAAU3N,cAAc4J,aAAa,GAAG,MAAMgE,QAAQC,GAAG,CAAC;YAC/D,IAAI,CAACjM,uBAAuB;YAC5B,IAAI,CAAC2E,+BAA+B;YACpC,IAAI,CAACyC,2BAA2B;SACjC;QAGD,MAAMrF,kBAAkB,IAAI,CAACmK,gCAAgC,CAC3DH,UACA3N,cACA4J;QAGF,MAAMnG,WAAW;YACfkK;YACA3N;YACA4J;YACAjG;QACF;QAEA,IAAI,CAAC1C,IAAI,CAAC,oBAAoBwC;QAC9B,OAAOA;IACT;IAIQxE,4BAA0C;QAChD,MAAM8O,WAAW,IAAIrR;QAErB,OAAO;YACLiJ,KAAK,CAACqI,UAAqBD,SAAS3N,GAAG,CAAC4N,QAAQvO,EAAE,EAAEuO;YACpDnK,KAAK,CAACpE,KAAesO,SAASlK,GAAG,CAACpE;YAClCwO,aAAa,CAACD,SAA2BE;gBACvC,OAAO9K,MAAMC,IAAI,CAAC0K,SAASzK,MAAM,IAAIS,MAAM,CAACoK,CAAAA,IAC1C,IAAI,CAACC,0BAA0B,CAACD,GAAGH,YAAYE;YAEnD;YACAG,WAAW,CAAC/P;gBACV,OAAO8E,MAAMC,IAAI,CAAC0K,SAASzK,MAAM,IAAIS,MAAM,CAACoK,CAAAA,IAAKA,EAAE7P,IAAI,KAAKA;YAC9D;YACAgQ,OAAO,CAACC;gBACN,MAAMC,SAASzQ,KAAKC,GAAG,KAAKuQ;gBAC5B,KAAK,MAAM,CAAC9O,IAAIuO,QAAQ,IAAID,SAAU;oBACpC,IAAIhQ,KAAKC,GAAG,KAAKuQ,SAASC,QAAQ;wBAChCT,SAAS1G,MAAM,CAAC5H;oBAClB;gBACF;YACF;YACAgP,QAAQ,IAAMrL,MAAMC,IAAI,CAAC0K,SAASzK,MAAM;YACxCoL,QAAQ,CAACC;gBACP,KAAK,MAAMX,WAAWW,iBAAkB;oBACtCZ,SAAS3N,GAAG,CAAC4N,QAAQvO,EAAE,EAAEuO;gBAC3B;YACF;QACF;IACF;IAEQ7N,wBAAwBwG,OAAc,EAAY;QACxD,OAAOvD,MAAMC,IAAI,CAAC;YAAE9B,QAAQ;QAAG,GAAG,IAAM,AAACC,CAAAA,KAAKoN,MAAM,KAAK,GAAE,IAAK;IAClE;IAEQ1P,oBAA0B;QAChC,IAAK,IAAIsI,IAAI,GAAGA,IAAI,IAAI,CAACrL,MAAM,CAACoF,MAAM,EAAEiG,IAAK;YAC3C,MAAMqH,QAAQ,IAAI,CAAC1S,MAAM,CAACqL,EAAE;YAC5B,MAAMjJ,WAAWiJ,MAAM,IAAI,KAAK,IAAI,CAACrL,MAAM,CAACqL,IAAI,EAAE,CAAChJ,SAAS;YAC5D,MAAMA,YAAYqQ,MAAMrQ,SAAS;YAGjC,MAAMsQ,QAAQtN,KAAKuN,IAAI,CAAC,IAAKxQ,CAAAA,WAAWC,SAAQ;YAChD,MAAM/B,UAAU2G,MAAMC,IAAI,CACxB;gBAAE9B,QAAQhD,WAAWC;YAAU,GAC/B,IAAM,AAACgD,CAAAA,KAAKoN,MAAM,KAAK,GAAE,IAAK,IAAIE;YAGpC,MAAMnS,SAASyG,MAAMC,IAAI,CAAC;gBAAE9B,QAAQ/C;YAAU,GAAG,IAAM;YAEvD,IAAI,CAAC/B,OAAO,CAAC2D,GAAG,CAAC,CAAC,MAAM,EAAEoH,GAAG,EAAE/K;YAC/B,IAAI,CAACE,MAAM,CAACyD,GAAG,CAAC,CAAC,MAAM,EAAEoH,GAAG,EAAE7K;QAChC;IACF;IAEQ8O,aAAgBuD,KAAU,EAAQ;QACxC,IAAK,IAAIxH,IAAIwH,MAAMzN,MAAM,GAAG,GAAGiG,IAAI,GAAGA,IAAK;YACzC,MAAMyH,IAAIzN,KAAK0N,KAAK,CAAC1N,KAAKoN,MAAM,KAAMpH,CAAAA,IAAI,CAAA;YAC1C,CAACwH,KAAK,CAACxH,EAAE,EAAEwH,KAAK,CAACC,EAAE,CAAC,GAAG;gBAACD,KAAK,CAACC,EAAE;gBAAED,KAAK,CAACxH,EAAE;aAAC;QAC7C;IACF;IAEQgF,gBAAgBL,KAAU,EAAY;QAE5C,IAAI,OAAOA,UAAU,YAAYA,MAAMxM,QAAQ,EAAE;YAC/C,OAAOwM,MAAMxM,QAAQ;QACvB;QAGA,OAAOyD,MAAMC,IAAI,CAAC;YAAE9B,QAAQ;QAAG,GAAG,IAAM;IAC1C;IAEQmL,aACNP,KAAe,EACf1P,OAAiB,EACjBE,MAAgB,EAChBC,MAAsB,EACZ;QAEV,MAAMyQ,SAAS,IAAIjK,MAAMxG,OAAO4B,SAAS,EAAE2Q,IAAI,CAAC;QAEhD,IAAK,IAAI3H,IAAI,GAAGA,IAAI5K,OAAO4B,SAAS,EAAEgJ,IAAK;YACzC,IAAIhE,MAAM7G,MAAM,CAAC6K,EAAE,IAAI;YACvB,IAAK,IAAIyH,IAAI,GAAGA,IAAI9C,MAAM5K,MAAM,EAAE0N,IAAK;gBACrC,MAAMG,cAAcH,IAAIrS,OAAO4B,SAAS,GAAGgJ;gBAC3ChE,OAAO2I,KAAK,CAAC8C,EAAE,GAAIxS,CAAAA,OAAO,CAAC2S,YAAY,IAAI,CAAA;YAC7C;YACA/B,MAAM,CAAC7F,EAAE,GAAG,IAAI,CAAC6H,eAAe,CAAC7L,KAAK5G,OAAO6B,UAAU;QACzD;QAGA,IAAI,IAAI,CAAClC,UAAU,IAAIK,OAAOS,OAAO,GAAG,GAAG;YACzC,IAAK,IAAImK,IAAI,GAAGA,IAAI6F,OAAO9L,MAAM,EAAEiG,IAAK;gBACtC,IAAIhG,KAAKoN,MAAM,KAAKhS,OAAOS,OAAO,EAAE;oBAClCgQ,MAAM,CAAC7F,EAAE,GAAG;gBACd;YACF;QACF;QAEA,OAAO6F;IACT;IAEQgC,gBAAgBC,CAAS,EAAE7Q,UAAkB,EAAU;QAC7D,OAAQA;YACN,KAAK;gBACH,OAAO+C,KAAK2D,GAAG,CAAC,GAAGmK;YACrB,KAAK;gBACH,OAAO9N,KAAK+N,IAAI,CAACD;YACnB,KAAK;gBACH,OAAO,IAAK,CAAA,IAAI9N,KAAKgO,GAAG,CAAC,CAACF,EAAC;YAC7B,KAAK;gBACH,OAAO,MAAMA,IAAK,CAAA,IAAI9N,KAAK+N,IAAI,CAAC/N,KAAKuN,IAAI,CAAC,IAAIvN,KAAKiO,EAAE,IAAKH,CAAAA,IAAI,WAAW9N,KAAKkO,GAAG,CAACJ,GAAG,EAAC,EAAE;YAC1F,KAAK;gBACH,OAAOA,IAAK,CAAA,IAAI9N,KAAKgO,GAAG,CAAC,CAACF,EAAC;YAC7B;gBACE,OAAOA;QACX;IACF;IAEQjD,cAAcH,WAAuB,EAAED,OAAc,EAAU;QACrE,IAAId,YAAY;QAEhB,IAAK,IAAI3D,IAAI,GAAGA,IAAI0E,YAAY3K,MAAM,EAAEiG,IAAK;YAC3C,MAAMmI,OAAOzD,WAAW,CAAC1E,EAAE;YAC3B,MAAMhH,SAAS4C,MAAMwM,OAAO,CAAC3D,OAAO,CAACzE,EAAE,IAAIyE,OAAO,CAACzE,EAAE,GAAG;gBAACyE,OAAO,CAACzE,EAAE;aAAC;YAGpE,IAAK,IAAIyH,IAAI,GAAGA,IAAIzN,KAAKC,GAAG,CAACkO,KAAKpO,MAAM,EAAEf,OAAOe,MAAM,GAAG0N,IAAK;gBAC7D,MAAMY,OAAOF,IAAI,CAACV,EAAE,GAAGzO,MAAM,CAACyO,EAAE;gBAChC9D,aAAa0E,OAAOA;YACtB;QACF;QAEA,OAAO1E,YAAYe,YAAY3K,MAAM;IACvC;IAEQ+K,kBAAkBJ,WAAuB,EAAED,OAAc,EAAU;QACzE,IAAIb,UAAU;QAEd,IAAK,IAAI5D,IAAI,GAAGA,IAAI0E,YAAY3K,MAAM,EAAEiG,IAAK;YAC3C,MAAMmI,OAAOzD,WAAW,CAAC1E,EAAE;YAC3B,MAAMhH,SAAS4C,MAAMwM,OAAO,CAAC3D,OAAO,CAACzE,EAAE,IAAIyE,OAAO,CAACzE,EAAE,GAAG;gBAACyE,OAAO,CAACzE,EAAE;aAAC;YAGpE,IAAIsI,gBAAgB;YACpB,IAAK,IAAIb,IAAI,GAAGA,IAAIzN,KAAKC,GAAG,CAACkO,KAAKpO,MAAM,EAAEf,OAAOe,MAAM,GAAG0N,IAAK;gBAC7D,IAAIzN,KAAKmD,GAAG,CAACgL,IAAI,CAACV,EAAE,GAAGzO,MAAM,CAACyO,EAAE,IAAI,KAAK;oBACvCa,gBAAgB;oBAChB;gBACF;YACF;YAEA,IAAIA,eAAe1E;QACrB;QAEA,OAAOA,UAAUc,YAAY3K,MAAM;IACrC;IAEQqL,yBAAyBV,WAAuB,EAAED,OAAc,EAAc;QACpF,MAAMY,YAAwB,EAAE;QAEhC,IAAK,IAAIrF,IAAI,GAAGA,IAAI0E,YAAY3K,MAAM,EAAEiG,IAAK;YAC3C,MAAMmI,OAAOzD,WAAW,CAAC1E,EAAE;YAC3B,MAAMhH,SAAS4C,MAAMwM,OAAO,CAAC3D,OAAO,CAACzE,EAAE,IAAIyE,OAAO,CAACzE,EAAE,GAAG;gBAACyE,OAAO,CAACzE,EAAE;aAAC;YACpE,MAAMuI,kBAA4B,EAAE;YAEpC,IAAK,IAAId,IAAI,GAAGA,IAAIU,KAAKpO,MAAM,EAAE0N,IAAK;gBACpC,MAAMe,YAAYf,IAAIzO,OAAOe,MAAM,GAAGf,MAAM,CAACyO,EAAE,GAAG;gBAClDc,gBAAgBzO,IAAI,CAAC,IAAKqO,CAAAA,IAAI,CAACV,EAAE,GAAGe,SAAQ;YAC9C;YAEAnD,UAAUvL,IAAI,CAACyO;QACjB;QAEA,OAAOlD;IACT;IAEQI,wBACNN,eAA2B,EAC3BlQ,OAAiB,EACjBE,MAAgB,EAChBC,MAAsB,EAKtB;QAEA,MAAMkQ,kBAAkB,IAAI1J,MAAM3G,QAAQ8E,MAAM,EAAE4N,IAAI,CAAC;QACvD,MAAMpC,gBAAgB,IAAI3J,MAAMzG,OAAO4E,MAAM,EAAE4N,IAAI,CAAC;QACpD,MAAMnC,iBAA6B,EAAE;QAKrC,IAAK,IAAIxF,IAAI,GAAGA,IAAImF,gBAAgBpL,MAAM,EAAEiG,IAAK;YAC/C,MAAMyI,uBAAuB,IAAI7M,MAAMxG,OAAO2B,QAAQ,EAAE4Q,IAAI,CAAC;YAE7D,IAAK,IAAIF,IAAI,GAAGA,IAAItC,eAAe,CAACnF,EAAE,CAACjG,MAAM,EAAE0N,IAAK;gBAClD,MAAMiB,OAAOvD,eAAe,CAACnF,EAAE,CAACyH,EAAE;gBAGlClC,aAAa,CAACkC,EAAE,IAAIiB;YAItB;YAEAlD,eAAe1L,IAAI,CAAC2O;QACtB;QAEA,OAAO;YAAEnD;YAAiBC;YAAeC;QAAe;IAC1D;IAEQE,cAAciD,OAAe,EAAE1T,OAAiB,EAAEoQ,SAAmB,EAAQ;QACnF,MAAMuD,KAAK,IAAI,CAAC/T,aAAa,CAACQ,YAAY;QAC1C,MAAMO,KAAK,IAAI,CAAChB,cAAc,CAACc,cAAc,CAACE,EAAE;QAEhD,IAAK,IAAIoK,IAAI,GAAGA,IAAI/K,QAAQ8E,MAAM,IAAIiG,IAAIqF,UAAUtL,MAAM,EAAEiG,IAAK;YAC/D/K,OAAO,CAAC+K,EAAE,IAAI4I,KAAMvD,CAAAA,SAAS,CAACrF,EAAE,GAAGpK,KAAKX,OAAO,CAAC+K,EAAE,AAAD;QACnD;QAEA,IAAI,CAAC/K,OAAO,CAAC2D,GAAG,CAAC+P,SAAS1T;IAC5B;IAEQ0Q,aAAagD,OAAe,EAAExT,MAAgB,EAAEkQ,SAAmB,EAAQ;QACjF,MAAMuD,KAAK,IAAI,CAAC/T,aAAa,CAACQ,YAAY;QAE1C,IAAK,IAAI2K,IAAI,GAAGA,IAAI7K,OAAO4E,MAAM,IAAIiG,IAAIqF,UAAUtL,MAAM,EAAEiG,IAAK;YAC9D7K,MAAM,CAAC6K,EAAE,IAAI4I,KAAKvD,SAAS,CAACrF,EAAE;QAChC;QAEA,IAAI,CAAC7K,MAAM,CAACyD,GAAG,CAAC+P,SAASxT;IAC3B;IAEA,MAAcgO,cAAcX,cAA4B,EAGrD;QACD,MAAMkC,cAAclC,eAAeuB,MAAM,CAACnK,GAAG,CAAC+K,CAAAA,QAAS,IAAI,CAACC,WAAW,CAACD;QACxE,MAAMtN,OAAO,IAAI,CAACwN,aAAa,CAACH,aAAalC,eAAe8B,OAAO;QACnE,MAAM/M,WAAW,IAAI,CAACuN,iBAAiB,CAACJ,aAAalC,eAAe8B,OAAO;QAE3E,OAAO;YAAEjN;YAAME;QAAS;IAC1B;IAEQuO,8BAA8BD,MAAgB,EAAU;QAE9D,MAAMgD,SAAS7O,KAAK2D,GAAG,IAAIkI;QAC3B,MAAMiD,SAAS9O,KAAKC,GAAG,IAAI4L;QAC3B,MAAMkD,QAAQF,SAASC;QAGvB,OAAO9O,KAAKC,GAAG,CAAC8O,OAAO;IACzB;IAEA,MAAc/C,+BACZrB,KAAU,EACVqE,KAAa,EACwC;QACrD,MAAMjD,eAA2D,EAAE;QAGnE,IAAK,IAAI/F,IAAI,GAAGA,IAAIgJ,OAAOhJ,IAAK;YAC9B,MAAMiJ,aAAa,IAAI,CAACC,eAAe,CAACvE,OAAO;YAC/C,MAAMkB,SAAS,IAAI,CAACjB,WAAW,CAACqE;YAChC,MAAM5G,aAAa,IAAI,CAACyD,6BAA6B,CAACD;YAEtDE,aAAajM,IAAI,CAAC;gBAAE+L;gBAAQxD;YAAW;QACzC;QAEA,OAAO0D,aAAa7E,IAAI,CAAC,CAACC,GAAGC,IAAMA,EAAEiB,UAAU,GAAGlB,EAAEkB,UAAU;IAChE;IAEQ6G,gBAAgBvE,KAAU,EAAEwE,UAAkB,EAAO;QAC3D,IAAI,OAAOxE,UAAU,YAAYA,MAAMxM,QAAQ,EAAE;YAC/C,MAAMiR,gBAAgBzE,MAAMxM,QAAQ,CAACyB,GAAG,CAAC,CAACyP,IACxCA,IAAI,AAACrP,CAAAA,KAAKoN,MAAM,KAAK,GAAE,IAAK+B;YAE9B,OAAO;gBAAE,GAAGxE,KAAK;gBAAExM,UAAUiR;YAAc;QAC7C;QAEA,OAAOzE;IACT;IAEQiC,2BAA2B0C,EAAW,EAAEC,EAAoB,EAAU;QAE5E,IAAIC,aAAa;QACjB,IAAItN,UAAU;QAEd,IAAIoN,GAAGxS,IAAI,KAAKyS,GAAGzS,IAAI,EAAE;YACvB0S,cAAc;QAChB;QACAtN;QAEA,IAAIqN,GAAGlH,UAAU,KAAKoH,WAAW;YAC/BD,cAAc,IAAIxP,KAAKmD,GAAG,CAACmM,GAAGjH,UAAU,GAAGkH,GAAGlH,UAAU;YACxDnG;QACF;QAEA,OAAOsN,aAAatN;IACtB;IAkBOwN,gBAML;QACA,OAAO;YACLC,WAAW;gBACTxT,OAAO,IAAI,CAACzB,KAAK,CAACyB,KAAK,CAACkC,IAAI;gBAC5BjC,OAAO,IAAI,CAAC1B,KAAK,CAAC0B,KAAK,CAACiC,IAAI;YAC9B;YACAxD,eAAe;gBAAE,GAAG,IAAI,CAACA,aAAa;YAAC;YACvCG,cAAc,IAAI,CAACA,YAAY;YAC/ByB,cAAc,IAAI,CAAC/B,KAAK,CAAC2B,QAAQ,CAACI,YAAY;YAC9CE,eAAe,IAAI,CAACjC,KAAK,CAAC2B,QAAQ,CAACM,aAAa;QAClD;IACF;IAKOiT,cAML;QACA,OAAO;YACLlV,OAAO,IAAI,CAACA,KAAK;YACjBO,SAAS4U,OAAOC,WAAW,CAAC,IAAI,CAAC7U,OAAO;YACxCE,QAAQ0U,OAAOC,WAAW,CAAC,IAAI,CAAC3U,MAAM;YACtCN,eAAe,IAAI,CAACA,aAAa;YACjCO,QAAQ,IAAI,CAACR,cAAc;QAC7B;IACF;IAKOmV,YAAYC,SAMlB,EAAQ;QACP,IAAI,CAACtV,KAAK,GAAGsV,UAAUtV,KAAK;QAC5B,IAAI,CAACO,OAAO,GAAG,IAAIC,IAAI2U,OAAOI,OAAO,CAACD,UAAU/U,OAAO;QACvD,IAAI,CAACE,MAAM,GAAG,IAAID,IAAI2U,OAAOI,OAAO,CAACD,UAAU7U,MAAM;QACrD,IAAI,CAACN,aAAa,GAAGmV,UAAUnV,aAAa;QAC5C,IAAI,CAACD,cAAc,GAAG;YAAE,GAAG,IAAI,CAACA,cAAc;YAAE,GAAGoV,UAAU5U,MAAM;QAAC;QAEpE,IAAI,CAACqE,IAAI,CAAC,kBAAkBuQ;IAC9B;IAGQ1O,4BAA4BX,QAAgB,EAAEuB,OAAY,EAAY;QAC5E,OAAO;YAAC;YAA+B;SAA+B;IACxE;IAEQT,uBAAuBb,UAAkB,EAAEE,UAAkB,EAAEE,UAAkB,EAAEE,QAAgB,EAAU;QACnH,MAAMgP,SAASlQ,KAAKC,GAAG,CAACW,YAAYE,YAAYE,YAAYE;QAC5D,IAAIgP,WAAWtP,YAAY,OAAO;QAClC,IAAIsP,WAAWpP,YAAY,OAAO;QAClC,IAAIoP,WAAWlP,YAAY,OAAO;QAClC,OAAO;IACT;IAEA,MAAcoB,gCAAgC/B,YAAiC,EAAEC,UAAiB,EAAgD;QAChJ,OAAO;YACL;gBACExD,MAAM;gBACNkC,QAAQ;oBAAC;oBAAW;iBAAU;gBAC9BuH,QAAQ;gBACR8B,YAAY;YACd;SACD;IACH;IAEA,MAAcd,gCAAgCvC,eAAoB,EAAEC,oBAAyB,EAAEC,aAAkB,EAAgD;QAC/J,OAAO;YACL;gBACEpI,MAAM;gBACNqT,UAAU;oBAAC;oBAAW;iBAAU;gBAChCC,SAAS;gBACTC,QAAQ;YACV;SACD;IACH;IAEA,MAAczI,uBAAuBH,SAAgB,EAAEC,gBAAqB,EAAEC,kBAAuB,EAAiB,CAEtH;IAEA,MAAcE,uBAAuBJ,SAAgB,EAAEC,gBAAqB,EAAEC,kBAAuB,EAAiB,CAEtH;IAEA,MAAcG,4BAA4BL,SAAgB,EAAEC,gBAAqB,EAAEC,kBAAuB,EAAiB,CAE3H;IAEA,MAAcI,6BAA6BN,SAAgB,EAAEC,gBAAqB,EAAEC,kBAAuB,EAAiB,CAE5H;IAEQM,2BAA2BR,SAAgB,EAAU;QAC3D,OAAOA,UAAU1F,MAAM,CAAC,CAACR,OAAOoL,IAAMpL,QAAQoL,EAAEtE,UAAU,GAAG,KAAK;IACpE;IAEQF,kBAAkBT,gBAAqB,EAAEC,kBAAuB,EAAEK,iBAAyB,EAA0C;QAC3I,IAAIN,iBAAiB/F,YAAY,GAAG,KAAK,OAAO;QAChD,IAAIqG,oBAAoB,KAAK,OAAO;QACpC,IAAIA,oBAAoB,KAAK,OAAO;QACpC,OAAO;IACT;IAEQsE,iCAAiCH,QAAa,EAAE3N,YAAiB,EAAE4J,YAAiB,EAAY;QACtG,MAAMjG,kBAAkB,EAAE;QAE1B,IAAIgK,SAASxK,YAAY,GAAG,KAAK;YAC/BQ,gBAAgBrC,IAAI,CAAC;QACvB;QAEA,IAAItB,aAAayG,oBAAoB,CAAClF,MAAM,GAAG,GAAG;YAChDoC,gBAAgBrC,IAAI,CAAC;QACvB;QAEA,IAAIsI,aAAaF,QAAQ,KAAK,UAAUE,aAAaF,QAAQ,KAAK,YAAY;YAC5E/F,gBAAgBrC,IAAI,CAAC;QACvB;QAEA,OAAOqC;IACT;AACF"}