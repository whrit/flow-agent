{"version":3,"sources":["../../../src/providers/utils.ts"],"sourcesContent":["/**\n * Utility functions for multi-LLM provider system\n */\n\nimport { ILogger } from '../core/logger.js';\nimport { ConfigManager } from '../config/config-manager.js';\nimport { ProviderManager, ProviderManagerConfig } from './provider-manager.js';\nimport { LLMProvider, LLMProviderConfig, FallbackStrategy } from './types.js';\n\n/**\n * Create a provider manager with default configuration\n */\nexport function createProviderManager(\n  logger: ILogger,\n  configManager: ConfigManager,\n  customConfig?: Partial<ProviderManagerConfig>\n): ProviderManager {\n  const defaultConfig = getDefaultProviderConfig();\n  const config = { ...defaultConfig, ...customConfig };\n  \n  // Load provider configs from environment\n  config.providers = loadProviderConfigs(config.providers);\n  \n  return new ProviderManager(logger, configManager, config);\n}\n\n/**\n * Get default provider configuration\n */\nexport function getDefaultProviderConfig(): ProviderManagerConfig {\n  const defaultProvider = (process.env.DEFAULT_LLM_PROVIDER as LLMProvider) || 'anthropic';\n  \n  return {\n    defaultProvider,\n    providers: {\n      anthropic: {\n        provider: 'anthropic',\n        apiKey: process.env.ANTHROPIC_API_KEY,\n        model: 'claude-3-sonnet-20240229',\n        temperature: 0.7,\n        maxTokens: 4096,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      openai: {\n        provider: 'openai',\n        apiKey: process.env.OPENAI_API_KEY,\n        model: 'gpt-4-turbo-preview',\n        temperature: 0.7,\n        maxTokens: 4096,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      google: {\n        provider: 'google',\n        apiKey: process.env.GOOGLE_AI_API_KEY,\n        model: 'gemini-pro',\n        temperature: 0.7,\n        maxTokens: 2048,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      cohere: {\n        provider: 'cohere',\n        apiKey: process.env.COHERE_API_KEY,\n        model: 'command',\n        temperature: 0.7,\n        maxTokens: 4096,\n        enableStreaming: true,\n        enableCaching: true,\n        timeout: 60000,\n        retryAttempts: 3,\n      },\n      ollama: {\n        provider: 'ollama',\n        apiUrl: process.env.OLLAMA_API_URL || 'http://localhost:11434',\n        model: 'llama-2-7b',\n        temperature: 0.7,\n        maxTokens: 2048,\n        enableStreaming: true,\n        enableCaching: false,\n        timeout: 120000, // Longer timeout for local models\n        retryAttempts: 2,\n      },\n    },\n    fallbackStrategy: getDefaultFallbackStrategy(),\n    loadBalancing: {\n      enabled: false,\n      strategy: 'round-robin',\n    },\n    costOptimization: {\n      enabled: true,\n      maxCostPerRequest: 1.0, // $1 max per request\n      preferredProviders: ['anthropic', 'openai'],\n    },\n    caching: {\n      enabled: true,\n      ttl: 3600, // 1 hour\n      maxSize: 100, // 100MB\n      strategy: 'lru',\n    },\n    monitoring: {\n      enabled: true,\n      metricsInterval: 60000, // 1 minute\n    },\n  };\n}\n\n/**\n * Get default fallback strategy\n */\nfunction getDefaultFallbackStrategy(): FallbackStrategy {\n  return {\n    name: 'default',\n    enabled: true,\n    maxAttempts: 3,\n    rules: [\n      {\n        condition: 'rate_limit',\n        fallbackProviders: ['openai', 'google', 'cohere', 'ollama'],\n        retryOriginal: true,\n        retryDelay: 60000, // 1 minute\n      },\n      {\n        condition: 'unavailable',\n        fallbackProviders: ['openai', 'google', 'anthropic', 'cohere'],\n        retryOriginal: true,\n        retryDelay: 30000, // 30 seconds\n      },\n      {\n        condition: 'timeout',\n        fallbackProviders: ['anthropic', 'openai', 'cohere'],\n        retryOriginal: false,\n      },\n      {\n        condition: 'cost',\n        fallbackProviders: ['ollama', 'cohere', 'google'],\n        retryOriginal: false,\n      },\n      {\n        condition: 'error',\n        errorCodes: ['AUTHENTICATION', 'MODEL_NOT_FOUND'],\n        fallbackProviders: [],\n        retryOriginal: false, // Don't retry auth errors\n      },\n    ],\n  };\n}\n\n/**\n * Load provider configurations from environment variables\n */\nfunction loadProviderConfigs(\n  configs: Record<LLMProvider, LLMProviderConfig>\n): Record<LLMProvider, LLMProviderConfig> {\n  const loaded = { ...configs };\n  \n  // Override with environment variables if present\n  for (const [provider, config] of Object.entries(loaded)) {\n    const envPrefix = `${provider.toUpperCase()}_`;\n    \n    // Check for provider-specific overrides\n    if (process.env[`${envPrefix}MODEL`]) {\n      config.model = process.env[`${envPrefix}MODEL`] as any;\n    }\n    if (process.env[`${envPrefix}TEMPERATURE`]) {\n      config.temperature = parseFloat(process.env[`${envPrefix}TEMPERATURE`]);\n    }\n    if (process.env[`${envPrefix}MAX_TOKENS`]) {\n      config.maxTokens = parseInt(process.env[`${envPrefix}MAX_TOKENS`], 10);\n    }\n    if (process.env[`${envPrefix}API_URL`]) {\n      config.apiUrl = process.env[`${envPrefix}API_URL`];\n    }\n  }\n  \n  return loaded;\n}\n\n/**\n * Validate provider configuration\n */\nexport function validateProviderConfig(config: LLMProviderConfig): string[] {\n  const errors: string[] = [];\n  \n  if (!config.provider) {\n    errors.push('Provider name is required');\n  }\n  \n  if (!config.model) {\n    errors.push('Model is required');\n  }\n  \n  if (config.temperature !== undefined) {\n    if (config.temperature < 0 || config.temperature > 2) {\n      errors.push('Temperature must be between 0 and 2');\n    }\n  }\n  \n  if (config.maxTokens !== undefined) {\n    if (config.maxTokens < 1 || config.maxTokens > 100000) {\n      errors.push('Max tokens must be between 1 and 100000');\n    }\n  }\n  \n  if (config.topP !== undefined) {\n    if (config.topP < 0 || config.topP > 1) {\n      errors.push('Top-p must be between 0 and 1');\n    }\n  }\n  \n  if (config.timeout !== undefined) {\n    if (config.timeout < 1000 || config.timeout > 600000) {\n      errors.push('Timeout must be between 1000ms and 600000ms');\n    }\n  }\n  \n  return errors;\n}\n\n/**\n * Get model recommendations based on use case\n */\nexport function getModelRecommendations(useCase: string): {\n  provider: LLMProvider;\n  model: string;\n  reasoning: string;\n}[] {\n  const recommendations: Record<string, any[]> = {\n    'code-generation': [\n      {\n        provider: 'anthropic',\n        model: 'claude-3-opus-20240229',\n        reasoning: 'Best for complex code generation with high accuracy',\n      },\n      {\n        provider: 'openai',\n        model: 'gpt-4-turbo-preview',\n        reasoning: 'Excellent code generation with function calling support',\n      },\n    ],\n    'chat': [\n      {\n        provider: 'anthropic',\n        model: 'claude-3-sonnet-20240229',\n        reasoning: 'Balanced performance for conversational AI',\n      },\n      {\n        provider: 'openai',\n        model: 'gpt-3.5-turbo',\n        reasoning: 'Fast and cost-effective for chat applications',\n      },\n    ],\n    'analysis': [\n      {\n        provider: 'anthropic',\n        model: 'claude-3-opus-20240229',\n        reasoning: 'Excellent for deep analysis and reasoning',\n      },\n      {\n        provider: 'google',\n        model: 'gemini-pro',\n        reasoning: 'Good for data analysis with multimodal support',\n      },\n    ],\n    'local': [\n      {\n        provider: 'ollama',\n        model: 'llama-2-13b',\n        reasoning: 'Good balance of performance and resource usage for local deployment',\n      },\n      {\n        provider: 'ollama',\n        model: 'mistral-7b',\n        reasoning: 'Fast local model with good performance',\n      },\n    ],\n    'budget': [\n      {\n        provider: 'ollama',\n        model: 'llama-2-7b',\n        reasoning: 'Free local model with no API costs',\n      },\n      {\n        provider: 'google',\n        model: 'gemini-pro',\n        reasoning: 'Very cost-effective cloud model',\n      },\n    ],\n  };\n  \n  return recommendations[useCase] || recommendations['chat'];\n}\n\n/**\n * Calculate estimated monthly cost based on usage\n */\nexport function estimateMonthlyCost(\n  provider: LLMProvider,\n  model: string,\n  estimatedRequests: number,\n  avgTokensPerRequest: number\n): {\n  promptCost: number;\n  completionCost: number;\n  totalCost: number;\n  currency: string;\n} {\n  // Get pricing from provider capabilities\n  // This is a simplified calculation\n  const pricing = getPricing(provider, model);\n  \n  if (!pricing) {\n    return {\n      promptCost: 0,\n      completionCost: 0,\n      totalCost: 0,\n      currency: 'USD',\n    };\n  }\n  \n  const promptTokens = avgTokensPerRequest * 0.7; // Assume 70% prompt\n  const completionTokens = avgTokensPerRequest * 0.3; // Assume 30% completion\n  \n  const promptCost = (promptTokens * estimatedRequests / 1000) * pricing.promptCostPer1k;\n  const completionCost = (completionTokens * estimatedRequests / 1000) * pricing.completionCostPer1k;\n  \n  return {\n    promptCost,\n    completionCost,\n    totalCost: promptCost + completionCost,\n    currency: pricing.currency,\n  };\n}\n\n/**\n * Get pricing for a specific provider and model\n */\nfunction getPricing(provider: LLMProvider, model: string): {\n  promptCostPer1k: number;\n  completionCostPer1k: number;\n  currency: string;\n} | null {\n  // This would typically come from provider capabilities\n  // Simplified for example\n  const pricingData: Record<string, any> = {\n    'anthropic:claude-3-opus-20240229': {\n      promptCostPer1k: 0.015,\n      completionCostPer1k: 0.075,\n      currency: 'USD',\n    },\n    'openai:gpt-4-turbo-preview': {\n      promptCostPer1k: 0.01,\n      completionCostPer1k: 0.03,\n      currency: 'USD',\n    },\n    'google:gemini-pro': {\n      promptCostPer1k: 0.00025,\n      completionCostPer1k: 0.0005,\n      currency: 'USD',\n    },\n    'ollama:llama-2-7b': {\n      promptCostPer1k: 0,\n      completionCostPer1k: 0,\n      currency: 'USD',\n    },\n  };\n  \n  return pricingData[`${provider}:${model}`] || null;\n}"],"names":["ProviderManager","createProviderManager","logger","configManager","customConfig","defaultConfig","getDefaultProviderConfig","config","providers","loadProviderConfigs","defaultProvider","process","env","DEFAULT_LLM_PROVIDER","anthropic","provider","apiKey","ANTHROPIC_API_KEY","model","temperature","maxTokens","enableStreaming","enableCaching","timeout","retryAttempts","openai","OPENAI_API_KEY","google","GOOGLE_AI_API_KEY","cohere","COHERE_API_KEY","ollama","apiUrl","OLLAMA_API_URL","fallbackStrategy","getDefaultFallbackStrategy","loadBalancing","enabled","strategy","costOptimization","maxCostPerRequest","preferredProviders","caching","ttl","maxSize","monitoring","metricsInterval","name","maxAttempts","rules","condition","fallbackProviders","retryOriginal","retryDelay","errorCodes","configs","loaded","Object","entries","envPrefix","toUpperCase","parseFloat","parseInt","validateProviderConfig","errors","push","undefined","topP","getModelRecommendations","useCase","recommendations","reasoning","estimateMonthlyCost","estimatedRequests","avgTokensPerRequest","pricing","getPricing","promptCost","completionCost","totalCost","currency","promptTokens","completionTokens","promptCostPer1k","completionCostPer1k","pricingData"],"mappings":"AAMA,SAASA,eAAe,QAA+B,wBAAwB;AAM/E,OAAO,SAASC,sBACdC,MAAe,EACfC,aAA4B,EAC5BC,YAA6C;IAE7C,MAAMC,gBAAgBC;IACtB,MAAMC,SAAS;QAAE,GAAGF,aAAa;QAAE,GAAGD,YAAY;IAAC;IAGnDG,OAAOC,SAAS,GAAGC,oBAAoBF,OAAOC,SAAS;IAEvD,OAAO,IAAIR,gBAAgBE,QAAQC,eAAeI;AACpD;AAKA,OAAO,SAASD;IACd,MAAMI,kBAAkB,AAACC,QAAQC,GAAG,CAACC,oBAAoB,IAAoB;IAE7E,OAAO;QACLH;QACAF,WAAW;YACTM,WAAW;gBACTC,UAAU;gBACVC,QAAQL,QAAQC,GAAG,CAACK,iBAAiB;gBACrCC,OAAO;gBACPC,aAAa;gBACbC,WAAW;gBACXC,iBAAiB;gBACjBC,eAAe;gBACfC,SAAS;gBACTC,eAAe;YACjB;YACAC,QAAQ;gBACNV,UAAU;gBACVC,QAAQL,QAAQC,GAAG,CAACc,cAAc;gBAClCR,OAAO;gBACPC,aAAa;gBACbC,WAAW;gBACXC,iBAAiB;gBACjBC,eAAe;gBACfC,SAAS;gBACTC,eAAe;YACjB;YACAG,QAAQ;gBACNZ,UAAU;gBACVC,QAAQL,QAAQC,GAAG,CAACgB,iBAAiB;gBACrCV,OAAO;gBACPC,aAAa;gBACbC,WAAW;gBACXC,iBAAiB;gBACjBC,eAAe;gBACfC,SAAS;gBACTC,eAAe;YACjB;YACAK,QAAQ;gBACNd,UAAU;gBACVC,QAAQL,QAAQC,GAAG,CAACkB,cAAc;gBAClCZ,OAAO;gBACPC,aAAa;gBACbC,WAAW;gBACXC,iBAAiB;gBACjBC,eAAe;gBACfC,SAAS;gBACTC,eAAe;YACjB;YACAO,QAAQ;gBACNhB,UAAU;gBACViB,QAAQrB,QAAQC,GAAG,CAACqB,cAAc,IAAI;gBACtCf,OAAO;gBACPC,aAAa;gBACbC,WAAW;gBACXC,iBAAiB;gBACjBC,eAAe;gBACfC,SAAS;gBACTC,eAAe;YACjB;QACF;QACAU,kBAAkBC;QAClBC,eAAe;YACbC,SAAS;YACTC,UAAU;QACZ;QACAC,kBAAkB;YAChBF,SAAS;YACTG,mBAAmB;YACnBC,oBAAoB;gBAAC;gBAAa;aAAS;QAC7C;QACAC,SAAS;YACPL,SAAS;YACTM,KAAK;YACLC,SAAS;YACTN,UAAU;QACZ;QACAO,YAAY;YACVR,SAAS;YACTS,iBAAiB;QACnB;IACF;AACF;AAKA,SAASX;IACP,OAAO;QACLY,MAAM;QACNV,SAAS;QACTW,aAAa;QACbC,OAAO;YACL;gBACEC,WAAW;gBACXC,mBAAmB;oBAAC;oBAAU;oBAAU;oBAAU;iBAAS;gBAC3DC,eAAe;gBACfC,YAAY;YACd;YACA;gBACEH,WAAW;gBACXC,mBAAmB;oBAAC;oBAAU;oBAAU;oBAAa;iBAAS;gBAC9DC,eAAe;gBACfC,YAAY;YACd;YACA;gBACEH,WAAW;gBACXC,mBAAmB;oBAAC;oBAAa;oBAAU;iBAAS;gBACpDC,eAAe;YACjB;YACA;gBACEF,WAAW;gBACXC,mBAAmB;oBAAC;oBAAU;oBAAU;iBAAS;gBACjDC,eAAe;YACjB;YACA;gBACEF,WAAW;gBACXI,YAAY;oBAAC;oBAAkB;iBAAkB;gBACjDH,mBAAmB,EAAE;gBACrBC,eAAe;YACjB;SACD;IACH;AACF;AAKA,SAAS3C,oBACP8C,OAA+C;IAE/C,MAAMC,SAAS;QAAE,GAAGD,OAAO;IAAC;IAG5B,KAAK,MAAM,CAACxC,UAAUR,OAAO,IAAIkD,OAAOC,OAAO,CAACF,QAAS;QACvD,MAAMG,YAAY,GAAG5C,SAAS6C,WAAW,GAAG,CAAC,CAAC;QAG9C,IAAIjD,QAAQC,GAAG,CAAC,GAAG+C,UAAU,KAAK,CAAC,CAAC,EAAE;YACpCpD,OAAOW,KAAK,GAAGP,QAAQC,GAAG,CAAC,GAAG+C,UAAU,KAAK,CAAC,CAAC;QACjD;QACA,IAAIhD,QAAQC,GAAG,CAAC,GAAG+C,UAAU,WAAW,CAAC,CAAC,EAAE;YAC1CpD,OAAOY,WAAW,GAAG0C,WAAWlD,QAAQC,GAAG,CAAC,GAAG+C,UAAU,WAAW,CAAC,CAAC;QACxE;QACA,IAAIhD,QAAQC,GAAG,CAAC,GAAG+C,UAAU,UAAU,CAAC,CAAC,EAAE;YACzCpD,OAAOa,SAAS,GAAG0C,SAASnD,QAAQC,GAAG,CAAC,GAAG+C,UAAU,UAAU,CAAC,CAAC,EAAE;QACrE;QACA,IAAIhD,QAAQC,GAAG,CAAC,GAAG+C,UAAU,OAAO,CAAC,CAAC,EAAE;YACtCpD,OAAOyB,MAAM,GAAGrB,QAAQC,GAAG,CAAC,GAAG+C,UAAU,OAAO,CAAC,CAAC;QACpD;IACF;IAEA,OAAOH;AACT;AAKA,OAAO,SAASO,uBAAuBxD,MAAyB;IAC9D,MAAMyD,SAAmB,EAAE;IAE3B,IAAI,CAACzD,OAAOQ,QAAQ,EAAE;QACpBiD,OAAOC,IAAI,CAAC;IACd;IAEA,IAAI,CAAC1D,OAAOW,KAAK,EAAE;QACjB8C,OAAOC,IAAI,CAAC;IACd;IAEA,IAAI1D,OAAOY,WAAW,KAAK+C,WAAW;QACpC,IAAI3D,OAAOY,WAAW,GAAG,KAAKZ,OAAOY,WAAW,GAAG,GAAG;YACpD6C,OAAOC,IAAI,CAAC;QACd;IACF;IAEA,IAAI1D,OAAOa,SAAS,KAAK8C,WAAW;QAClC,IAAI3D,OAAOa,SAAS,GAAG,KAAKb,OAAOa,SAAS,GAAG,QAAQ;YACrD4C,OAAOC,IAAI,CAAC;QACd;IACF;IAEA,IAAI1D,OAAO4D,IAAI,KAAKD,WAAW;QAC7B,IAAI3D,OAAO4D,IAAI,GAAG,KAAK5D,OAAO4D,IAAI,GAAG,GAAG;YACtCH,OAAOC,IAAI,CAAC;QACd;IACF;IAEA,IAAI1D,OAAOgB,OAAO,KAAK2C,WAAW;QAChC,IAAI3D,OAAOgB,OAAO,GAAG,QAAQhB,OAAOgB,OAAO,GAAG,QAAQ;YACpDyC,OAAOC,IAAI,CAAC;QACd;IACF;IAEA,OAAOD;AACT;AAKA,OAAO,SAASI,wBAAwBC,OAAe;IAKrD,MAAMC,kBAAyC;QAC7C,mBAAmB;YACjB;gBACEvD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;YACA;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;SACD;QACD,QAAQ;YACN;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;YACA;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;SACD;QACD,YAAY;YACV;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;YACA;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;SACD;QACD,SAAS;YACP;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;YACA;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;SACD;QACD,UAAU;YACR;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;YACA;gBACExD,UAAU;gBACVG,OAAO;gBACPqD,WAAW;YACb;SACD;IACH;IAEA,OAAOD,eAAe,CAACD,QAAQ,IAAIC,eAAe,CAAC,OAAO;AAC5D;AAKA,OAAO,SAASE,oBACdzD,QAAqB,EACrBG,KAAa,EACbuD,iBAAyB,EACzBC,mBAA2B;IAS3B,MAAMC,UAAUC,WAAW7D,UAAUG;IAErC,IAAI,CAACyD,SAAS;QACZ,OAAO;YACLE,YAAY;YACZC,gBAAgB;YAChBC,WAAW;YACXC,UAAU;QACZ;IACF;IAEA,MAAMC,eAAeP,sBAAsB;IAC3C,MAAMQ,mBAAmBR,sBAAsB;IAE/C,MAAMG,aAAa,AAACI,eAAeR,oBAAoB,OAAQE,QAAQQ,eAAe;IACtF,MAAML,iBAAiB,AAACI,mBAAmBT,oBAAoB,OAAQE,QAAQS,mBAAmB;IAElG,OAAO;QACLP;QACAC;QACAC,WAAWF,aAAaC;QACxBE,UAAUL,QAAQK,QAAQ;IAC5B;AACF;AAKA,SAASJ,WAAW7D,QAAqB,EAAEG,KAAa;IAOtD,MAAMmE,cAAmC;QACvC,oCAAoC;YAClCF,iBAAiB;YACjBC,qBAAqB;YACrBJ,UAAU;QACZ;QACA,8BAA8B;YAC5BG,iBAAiB;YACjBC,qBAAqB;YACrBJ,UAAU;QACZ;QACA,qBAAqB;YACnBG,iBAAiB;YACjBC,qBAAqB;YACrBJ,UAAU;QACZ;QACA,qBAAqB;YACnBG,iBAAiB;YACjBC,qBAAqB;YACrBJ,UAAU;QACZ;IACF;IAEA,OAAOK,WAAW,CAAC,GAAGtE,SAAS,CAAC,EAAEG,OAAO,CAAC,IAAI;AAChD"}