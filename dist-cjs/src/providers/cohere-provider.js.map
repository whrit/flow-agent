{"version":3,"sources":["../../../src/providers/cohere-provider.ts"],"sourcesContent":["/**\n * Cohere Provider Implementation\n * Supports Command, Generate, and other Cohere models\n */\n\nimport { BaseProvider } from './base-provider.js';\nimport {\n  LLMProvider,\n  LLMModel,\n  LLMRequest,\n  LLMResponse,\n  LLMStreamEvent,\n  ModelInfo,\n  ProviderCapabilities,\n  HealthCheckResult,\n  LLMProviderError,\n  RateLimitError,\n  AuthenticationError,\n} from './types.js';\n\ninterface CohereGenerateRequest {\n  model: string;\n  prompt?: string;\n  messages?: Array<{\n    role: 'USER' | 'CHATBOT' | 'SYSTEM';\n    message: string;\n  }>;\n  preamble?: string;\n  temperature?: number;\n  max_tokens?: number;\n  k?: number;\n  p?: number;\n  frequency_penalty?: number;\n  presence_penalty?: number;\n  stop_sequences?: string[];\n  stream?: boolean;\n}\n\ninterface CohereGenerateResponse {\n  id: string;\n  generations: Array<{\n    id: string;\n    text: string;\n    finish_reason: string;\n  }>;\n  prompt: string;\n  meta: {\n    api_version: {\n      version: string;\n    };\n    billed_units: {\n      input_tokens: number;\n      output_tokens: number;\n    };\n  };\n}\n\ninterface CohereChatResponse {\n  text: string;\n  generation_id: string;\n  finish_reason: string;\n  meta: {\n    api_version: {\n      version: string;\n    };\n    billed_units: {\n      input_tokens: number;\n      output_tokens: number;\n    };\n  };\n}\n\nexport class CohereProvider extends BaseProvider {\n  readonly name: LLMProvider = 'cohere';\n  readonly capabilities: ProviderCapabilities = {\n    supportedModels: [\n      'command',\n      'command-light',\n      'command-nightly',\n      'generate-xlarge',\n      'generate-medium',\n    ],\n    maxContextLength: {\n      'command': 4096,\n      'command-light': 4096,\n      'command-nightly': 8192,\n      'generate-xlarge': 2048,\n      'generate-medium': 2048,\n    } as Record<LLMModel, number>,\n    maxOutputTokens: {\n      'command': 4096,\n      'command-light': 4096,\n      'command-nightly': 4096,\n      'generate-xlarge': 2048,\n      'generate-medium': 2048,\n    } as Record<LLMModel, number>,\n    supportsStreaming: true,\n    supportsFunctionCalling: false,\n    supportsSystemMessages: true,\n    supportsVision: false,\n    supportsAudio: false,\n    supportsTools: true,\n    supportsFineTuning: true,\n    supportsEmbeddings: true,\n    supportsLogprobs: true,\n    supportsBatching: false,\n    rateLimit: {\n      requestsPerMinute: 100,\n      tokensPerMinute: 100000,\n      concurrentRequests: 20,\n    },\n    pricing: {\n      'command': {\n        promptCostPer1k: 0.0015,\n        completionCostPer1k: 0.0015,\n        currency: 'USD',\n      },\n      'command-light': {\n        promptCostPer1k: 0.00015,\n        completionCostPer1k: 0.00015,\n        currency: 'USD',\n      },\n      'command-nightly': {\n        promptCostPer1k: 0.0015,\n        completionCostPer1k: 0.0015,\n        currency: 'USD',\n      },\n      'generate-xlarge': {\n        promptCostPer1k: 0.005,\n        completionCostPer1k: 0.015,\n        currency: 'USD',\n      },\n      'generate-medium': {\n        promptCostPer1k: 0.001,\n        completionCostPer1k: 0.005,\n        currency: 'USD',\n      },\n    },\n  };\n\n  private baseUrl = 'https://api.cohere.ai/v1';\n  private headers: Record<string, string> = {};\n\n  protected async doInitialize(): Promise<void> {\n    if (!this.config.apiKey) {\n      throw new AuthenticationError('Cohere API key is required', 'cohere');\n    }\n\n    this.headers = {\n      'Authorization': `Bearer ${this.config.apiKey}`,\n      'Content-Type': 'application/json',\n      'Accept': 'application/json',\n    };\n  }\n\n  protected async doComplete(request: LLMRequest): Promise<LLMResponse> {\n    const isChat = request.messages.length > 1 || request.messages[0].role !== 'user';\n    const model = request.model || this.config.model;\n    \n    if (isChat && model.startsWith('command')) {\n      return this.doChatComplete(request);\n    } else {\n      return this.doGenerateComplete(request);\n    }\n  }\n\n  private async doChatComplete(request: LLMRequest): Promise<LLMResponse> {\n    const messages = this.convertMessages(request.messages);\n    const systemMessage = request.messages.find(m => m.role === 'system');\n    \n    const cohereRequest = {\n      model: this.mapToCohereModel(request.model || this.config.model),\n      messages,\n      preamble: systemMessage?.content,\n      temperature: request.temperature ?? this.config.temperature,\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\n      k: request.topK ?? this.config.topK,\n      p: request.topP ?? this.config.topP,\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\n      stream: false,\n    };\n\n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), this.config.timeout || 60000);\n\n    try {\n      const response = await fetch(`${this.baseUrl}/chat`, {\n        method: 'POST',\n        headers: this.headers,\n        body: JSON.stringify(cohereRequest),\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeout);\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const data: CohereChatResponse = await response.json();\n      \n      // Calculate cost\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\n      const promptCost = (data.meta.billed_units.input_tokens / 1000) * pricing.promptCostPer1k;\n      const completionCost = (data.meta.billed_units.output_tokens / 1000) * pricing.completionCostPer1k;\n\n      return {\n        id: data.generation_id,\n        model: request.model || this.config.model,\n        provider: 'cohere',\n        content: data.text,\n        usage: {\n          promptTokens: data.meta.billed_units.input_tokens,\n          completionTokens: data.meta.billed_units.output_tokens,\n          totalTokens: data.meta.billed_units.input_tokens + data.meta.billed_units.output_tokens,\n        },\n        cost: {\n          promptCost,\n          completionCost,\n          totalCost: promptCost + completionCost,\n          currency: 'USD',\n        },\n        finishReason: this.mapFinishReason(data.finish_reason),\n      };\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    }\n  }\n\n  private async doGenerateComplete(request: LLMRequest): Promise<LLMResponse> {\n    // For generate endpoint, concatenate messages into a prompt\n    const prompt = request.messages.map(m => m.content).join('\\n\\n');\n    \n    const cohereRequest: CohereGenerateRequest = {\n      model: this.mapToCohereModel(request.model || this.config.model),\n      prompt,\n      temperature: request.temperature ?? this.config.temperature,\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\n      k: request.topK ?? this.config.topK,\n      p: request.topP ?? this.config.topP,\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\n      stream: false,\n    };\n\n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), this.config.timeout || 60000);\n\n    try {\n      const response = await fetch(`${this.baseUrl}/generate`, {\n        method: 'POST',\n        headers: this.headers,\n        body: JSON.stringify(cohereRequest),\n        signal: controller.signal,\n      });\n\n      clearTimeout(timeout);\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const data: CohereGenerateResponse = await response.json();\n      const generation = data.generations[0];\n      \n      // Calculate cost\n      const pricing = this.capabilities.pricing![request.model || this.config.model];\n      const promptCost = (data.meta.billed_units.input_tokens / 1000) * pricing.promptCostPer1k;\n      const completionCost = (data.meta.billed_units.output_tokens / 1000) * pricing.completionCostPer1k;\n\n      return {\n        id: generation.id,\n        model: request.model || this.config.model,\n        provider: 'cohere',\n        content: generation.text,\n        usage: {\n          promptTokens: data.meta.billed_units.input_tokens,\n          completionTokens: data.meta.billed_units.output_tokens,\n          totalTokens: data.meta.billed_units.input_tokens + data.meta.billed_units.output_tokens,\n        },\n        cost: {\n          promptCost,\n          completionCost,\n          totalCost: promptCost + completionCost,\n          currency: 'USD',\n        },\n        finishReason: this.mapFinishReason(generation.finish_reason),\n      };\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    }\n  }\n\n  protected async *doStreamComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\n    const isChat = request.messages.length > 1 || request.messages[0].role !== 'user';\n    const model = request.model || this.config.model;\n    \n    if (isChat && model.startsWith('command')) {\n      yield* this.streamChatComplete(request);\n    } else {\n      yield* this.streamGenerateComplete(request);\n    }\n  }\n\n  private async *streamChatComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\n    const messages = this.convertMessages(request.messages);\n    const systemMessage = request.messages.find(m => m.role === 'system');\n    \n    const cohereRequest = {\n      model: this.mapToCohereModel(request.model || this.config.model),\n      messages,\n      preamble: systemMessage?.content,\n      temperature: request.temperature ?? this.config.temperature,\n      max_tokens: request.maxTokens ?? this.config.maxTokens,\n      k: request.topK ?? this.config.topK,\n      p: request.topP ?? this.config.topP,\n      frequency_penalty: request.frequencyPenalty ?? this.config.frequencyPenalty,\n      presence_penalty: request.presencePenalty ?? this.config.presencePenalty,\n      stop_sequences: request.stopSequences ?? this.config.stopSequences,\n      stream: true,\n    };\n\n    const controller = new AbortController();\n    const timeout = setTimeout(() => controller.abort(), (this.config.timeout || 60000) * 2);\n\n    try {\n      const response = await fetch(`${this.baseUrl}/chat`, {\n        method: 'POST',\n        headers: this.headers,\n        body: JSON.stringify(cohereRequest),\n        signal: controller.signal,\n      });\n\n      if (!response.ok) {\n        await this.handleErrorResponse(response);\n      }\n\n      const reader = response.body!.getReader();\n      const decoder = new TextDecoder();\n      let buffer = '';\n      let totalContent = '';\n\n      while (true) {\n        const { done, value } = await reader.read();\n        if (done) break;\n\n        buffer += decoder.decode(value, { stream: true });\n        const lines = buffer.split('\\n');\n        buffer = lines.pop() || '';\n\n        for (const line of lines) {\n          if (line.trim() === '') continue;\n          \n          try {\n            const data = JSON.parse(line);\n            \n            if (data.text) {\n              totalContent += data.text;\n              yield {\n                type: 'content',\n                delta: { content: data.text },\n              };\n            }\n            \n            if (data.is_finished) {\n              // Estimate tokens for streaming\n              const promptTokens = this.estimateTokens(JSON.stringify(request.messages));\n              const completionTokens = this.estimateTokens(totalContent);\n              \n              const pricing = this.capabilities.pricing![request.model || this.config.model];\n              const promptCost = (promptTokens / 1000) * pricing.promptCostPer1k;\n              const completionCost = (completionTokens / 1000) * pricing.completionCostPer1k;\n\n              yield {\n                type: 'done',\n                usage: {\n                  promptTokens,\n                  completionTokens,\n                  totalTokens: promptTokens + completionTokens,\n                },\n                cost: {\n                  promptCost,\n                  completionCost,\n                  totalCost: promptCost + completionCost,\n                  currency: 'USD',\n                },\n              };\n            }\n          } catch (e) {\n            this.logger.warn('Failed to parse Cohere stream chunk', { line, error: e });\n          }\n        }\n      }\n    } catch (error) {\n      clearTimeout(timeout);\n      throw this.transformError(error);\n    } finally {\n      clearTimeout(timeout);\n    }\n  }\n\n  private async *streamGenerateComplete(request: LLMRequest): AsyncIterable<LLMStreamEvent> {\n    // Similar implementation for generate endpoint\n    // Omitted for brevity - follows same pattern as streamChatComplete\n    yield* this.streamChatComplete(request); // Fallback to chat for now\n  }\n\n  async listModels(): Promise<LLMModel[]> {\n    return this.capabilities.supportedModels;\n  }\n\n  async getModelInfo(model: LLMModel): Promise<ModelInfo> {\n    return {\n      model,\n      name: model,\n      description: this.getModelDescription(model),\n      contextLength: this.capabilities.maxContextLength[model] || 4096,\n      maxOutputTokens: this.capabilities.maxOutputTokens[model] || 4096,\n      supportedFeatures: [\n        'chat',\n        'completion',\n        'embeddings',\n        ...(model.startsWith('command') ? ['tools'] : []),\n      ],\n      pricing: this.capabilities.pricing![model],\n    };\n  }\n\n  protected async doHealthCheck(): Promise<HealthCheckResult> {\n    try {\n      const response = await fetch(`${this.baseUrl}/check-api-key`, {\n        method: 'POST',\n        headers: this.headers,\n      });\n\n      if (!response.ok) {\n        throw new Error(`Health check failed: ${response.status}`);\n      }\n\n      return {\n        healthy: true,\n        timestamp: new Date(),\n      };\n    } catch (error) {\n      return {\n        healthy: false,\n        error: error instanceof Error ? error.message : 'Unknown error',\n        timestamp: new Date(),\n      };\n    }\n  }\n\n  private convertMessages(messages: LLMRequest['messages']) {\n    return messages\n      .filter(m => m.role !== 'system')\n      .map(m => ({\n        role: m.role === 'assistant' ? 'CHATBOT' as const : 'USER' as const,\n        message: m.content,\n      }));\n  }\n\n  private mapToCohereModel(model: LLMModel): string {\n    const modelMap: Record<string, string> = {\n      'command': 'command',\n      'command-light': 'command-light',\n      'command-nightly': 'command-nightly',\n      'generate-xlarge': 'xlarge',\n      'generate-medium': 'medium',\n    };\n    return modelMap[model] || model;\n  }\n\n  private mapFinishReason(reason: string): 'stop' | 'length' {\n    return reason === 'COMPLETE' ? 'stop' : 'length';\n  }\n\n  private getModelDescription(model: LLMModel): string {\n    const descriptions: Record<string, string> = {\n      'command': 'Powerful model for complex tasks',\n      'command-light': 'Faster, lightweight version of Command',\n      'command-nightly': 'Latest experimental Command model',\n      'generate-xlarge': 'Large generation model',\n      'generate-medium': 'Medium generation model',\n    };\n    return descriptions[model] || 'Cohere language model';\n  }\n\n  private async handleErrorResponse(response: Response): Promise<void> {\n    const errorText = await response.text();\n    let errorData: any;\n\n    try {\n      errorData = JSON.parse(errorText);\n    } catch {\n      errorData = { message: errorText };\n    }\n\n    const message = errorData.message || 'Unknown error';\n\n    switch (response.status) {\n      case 401:\n        throw new AuthenticationError(message, 'cohere', errorData);\n      case 429:\n        throw new RateLimitError(message, 'cohere', undefined, errorData);\n      default:\n        throw new LLMProviderError(\n          message,\n          `COHERE_${response.status}`,\n          'cohere',\n          response.status,\n          response.status >= 500,\n          errorData\n        );\n    }\n  }\n}"],"names":["BaseProvider","LLMProviderError","RateLimitError","AuthenticationError","CohereProvider","name","capabilities","supportedModels","maxContextLength","maxOutputTokens","supportsStreaming","supportsFunctionCalling","supportsSystemMessages","supportsVision","supportsAudio","supportsTools","supportsFineTuning","supportsEmbeddings","supportsLogprobs","supportsBatching","rateLimit","requestsPerMinute","tokensPerMinute","concurrentRequests","pricing","promptCostPer1k","completionCostPer1k","currency","baseUrl","headers","doInitialize","config","apiKey","doComplete","request","isChat","messages","length","role","model","startsWith","doChatComplete","doGenerateComplete","convertMessages","systemMessage","find","m","cohereRequest","mapToCohereModel","preamble","content","temperature","max_tokens","maxTokens","k","topK","p","topP","frequency_penalty","frequencyPenalty","presence_penalty","presencePenalty","stop_sequences","stopSequences","stream","controller","AbortController","timeout","setTimeout","abort","response","fetch","method","body","JSON","stringify","signal","clearTimeout","ok","handleErrorResponse","data","json","promptCost","meta","billed_units","input_tokens","completionCost","output_tokens","id","generation_id","provider","text","usage","promptTokens","completionTokens","totalTokens","cost","totalCost","finishReason","mapFinishReason","finish_reason","error","transformError","prompt","map","join","generation","generations","doStreamComplete","streamChatComplete","streamGenerateComplete","reader","getReader","decoder","TextDecoder","buffer","totalContent","done","value","read","decode","lines","split","pop","line","trim","parse","type","delta","is_finished","estimateTokens","e","logger","warn","listModels","getModelInfo","description","getModelDescription","contextLength","supportedFeatures","doHealthCheck","Error","status","healthy","timestamp","Date","message","filter","modelMap","reason","descriptions","errorText","errorData","undefined"],"mappings":"AAKA,SAASA,YAAY,QAAQ,qBAAqB;AAClD,SASEC,gBAAgB,EAChBC,cAAc,EACdC,mBAAmB,QACd,aAAa;AAsDpB,OAAO,MAAMC,uBAAuBJ;IACzBK,OAAoB,SAAS;IAC7BC,eAAqC;QAC5CC,iBAAiB;YACf;YACA;YACA;YACA;YACA;SACD;QACDC,kBAAkB;YAChB,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACAC,iBAAiB;YACf,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACAC,mBAAmB;QACnBC,yBAAyB;QACzBC,wBAAwB;QACxBC,gBAAgB;QAChBC,eAAe;QACfC,eAAe;QACfC,oBAAoB;QACpBC,oBAAoB;QACpBC,kBAAkB;QAClBC,kBAAkB;QAClBC,WAAW;YACTC,mBAAmB;YACnBC,iBAAiB;YACjBC,oBAAoB;QACtB;QACAC,SAAS;YACP,WAAW;gBACTC,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,iBAAiB;gBACfF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,mBAAmB;gBACjBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,mBAAmB;gBACjBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;YACA,mBAAmB;gBACjBF,iBAAiB;gBACjBC,qBAAqB;gBACrBC,UAAU;YACZ;QACF;IACF,EAAE;IAEMC,UAAU,2BAA2B;IACrCC,UAAkC,CAAC,EAAE;IAE7C,MAAgBC,eAA8B;QAC5C,IAAI,CAAC,IAAI,CAACC,MAAM,CAACC,MAAM,EAAE;YACvB,MAAM,IAAI7B,oBAAoB,8BAA8B;QAC9D;QAEA,IAAI,CAAC0B,OAAO,GAAG;YACb,iBAAiB,CAAC,OAAO,EAAE,IAAI,CAACE,MAAM,CAACC,MAAM,EAAE;YAC/C,gBAAgB;YAChB,UAAU;QACZ;IACF;IAEA,MAAgBC,WAAWC,OAAmB,EAAwB;QACpE,MAAMC,SAASD,QAAQE,QAAQ,CAACC,MAAM,GAAG,KAAKH,QAAQE,QAAQ,CAAC,EAAE,CAACE,IAAI,KAAK;QAC3E,MAAMC,QAAQL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;QAEhD,IAAIJ,UAAUI,MAAMC,UAAU,CAAC,YAAY;YACzC,OAAO,IAAI,CAACC,cAAc,CAACP;QAC7B,OAAO;YACL,OAAO,IAAI,CAACQ,kBAAkB,CAACR;QACjC;IACF;IAEA,MAAcO,eAAeP,OAAmB,EAAwB;QACtE,MAAME,WAAW,IAAI,CAACO,eAAe,CAACT,QAAQE,QAAQ;QACtD,MAAMQ,gBAAgBV,QAAQE,QAAQ,CAACS,IAAI,CAACC,CAAAA,IAAKA,EAAER,IAAI,KAAK;QAE5D,MAAMS,gBAAgB;YACpBR,OAAO,IAAI,CAACS,gBAAgB,CAACd,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;YAC/DH;YACAa,UAAUL,eAAeM;YACzBC,aAAajB,QAAQiB,WAAW,IAAI,IAAI,CAACpB,MAAM,CAACoB,WAAW;YAC3DC,YAAYlB,QAAQmB,SAAS,IAAI,IAAI,CAACtB,MAAM,CAACsB,SAAS;YACtDC,GAAGpB,QAAQqB,IAAI,IAAI,IAAI,CAACxB,MAAM,CAACwB,IAAI;YACnCC,GAAGtB,QAAQuB,IAAI,IAAI,IAAI,CAAC1B,MAAM,CAAC0B,IAAI;YACnCC,mBAAmBxB,QAAQyB,gBAAgB,IAAI,IAAI,CAAC5B,MAAM,CAAC4B,gBAAgB;YAC3EC,kBAAkB1B,QAAQ2B,eAAe,IAAI,IAAI,CAAC9B,MAAM,CAAC8B,eAAe;YACxEC,gBAAgB5B,QAAQ6B,aAAa,IAAI,IAAI,CAAChC,MAAM,CAACgC,aAAa;YAClEC,QAAQ;QACV;QAEA,MAAMC,aAAa,IAAIC;QACvB,MAAMC,UAAUC,WAAW,IAAMH,WAAWI,KAAK,IAAI,IAAI,CAACtC,MAAM,CAACoC,OAAO,IAAI;QAE5E,IAAI;YACF,MAAMG,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,KAAK,CAAC,EAAE;gBACnD4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;gBACrB4C,MAAMC,KAAKC,SAAS,CAAC5B;gBACrB6B,QAAQX,WAAWW,MAAM;YAC3B;YAEAC,aAAaV;YAEb,IAAI,CAACG,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI,CAACC,mBAAmB,CAACT;YACjC;YAEA,MAAMU,OAA2B,MAAMV,SAASW,IAAI;YAGpD,MAAMzD,UAAU,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACU,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK,CAAC;YAC9E,MAAM2C,aAAa,AAACF,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAG,OAAQ7D,QAAQC,eAAe;YACzF,MAAM6D,iBAAiB,AAACN,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa,GAAG,OAAQ/D,QAAQE,mBAAmB;YAElG,OAAO;gBACL8D,IAAIR,KAAKS,aAAa;gBACtBlD,OAAOL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;gBACzCmD,UAAU;gBACVxC,SAAS8B,KAAKW,IAAI;gBAClBC,OAAO;oBACLC,cAAcb,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY;oBACjDS,kBAAkBd,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;oBACtDQ,aAAaf,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAGL,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;gBACzF;gBACAS,MAAM;oBACJd;oBACAI;oBACAW,WAAWf,aAAaI;oBACxB3D,UAAU;gBACZ;gBACAuE,cAAc,IAAI,CAACC,eAAe,CAACnB,KAAKoB,aAAa;YACvD;QACF,EAAE,OAAOC,OAAO;YACdxB,aAAaV;YACb,MAAM,IAAI,CAACmC,cAAc,CAACD;QAC5B;IACF;IAEA,MAAc3D,mBAAmBR,OAAmB,EAAwB;QAE1E,MAAMqE,SAASrE,QAAQE,QAAQ,CAACoE,GAAG,CAAC1D,CAAAA,IAAKA,EAAEI,OAAO,EAAEuD,IAAI,CAAC;QAEzD,MAAM1D,gBAAuC;YAC3CR,OAAO,IAAI,CAACS,gBAAgB,CAACd,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;YAC/DgE;YACApD,aAAajB,QAAQiB,WAAW,IAAI,IAAI,CAACpB,MAAM,CAACoB,WAAW;YAC3DC,YAAYlB,QAAQmB,SAAS,IAAI,IAAI,CAACtB,MAAM,CAACsB,SAAS;YACtDC,GAAGpB,QAAQqB,IAAI,IAAI,IAAI,CAACxB,MAAM,CAACwB,IAAI;YACnCC,GAAGtB,QAAQuB,IAAI,IAAI,IAAI,CAAC1B,MAAM,CAAC0B,IAAI;YACnCC,mBAAmBxB,QAAQyB,gBAAgB,IAAI,IAAI,CAAC5B,MAAM,CAAC4B,gBAAgB;YAC3EC,kBAAkB1B,QAAQ2B,eAAe,IAAI,IAAI,CAAC9B,MAAM,CAAC8B,eAAe;YACxEC,gBAAgB5B,QAAQ6B,aAAa,IAAI,IAAI,CAAChC,MAAM,CAACgC,aAAa;YAClEC,QAAQ;QACV;QAEA,MAAMC,aAAa,IAAIC;QACvB,MAAMC,UAAUC,WAAW,IAAMH,WAAWI,KAAK,IAAI,IAAI,CAACtC,MAAM,CAACoC,OAAO,IAAI;QAE5E,IAAI;YACF,MAAMG,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,SAAS,CAAC,EAAE;gBACvD4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;gBACrB4C,MAAMC,KAAKC,SAAS,CAAC5B;gBACrB6B,QAAQX,WAAWW,MAAM;YAC3B;YAEAC,aAAaV;YAEb,IAAI,CAACG,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI,CAACC,mBAAmB,CAACT;YACjC;YAEA,MAAMU,OAA+B,MAAMV,SAASW,IAAI;YACxD,MAAMyB,aAAa1B,KAAK2B,WAAW,CAAC,EAAE;YAGtC,MAAMnF,UAAU,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACU,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK,CAAC;YAC9E,MAAM2C,aAAa,AAACF,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAG,OAAQ7D,QAAQC,eAAe;YACzF,MAAM6D,iBAAiB,AAACN,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa,GAAG,OAAQ/D,QAAQE,mBAAmB;YAElG,OAAO;gBACL8D,IAAIkB,WAAWlB,EAAE;gBACjBjD,OAAOL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;gBACzCmD,UAAU;gBACVxC,SAASwD,WAAWf,IAAI;gBACxBC,OAAO;oBACLC,cAAcb,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY;oBACjDS,kBAAkBd,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;oBACtDQ,aAAaf,KAAKG,IAAI,CAACC,YAAY,CAACC,YAAY,GAAGL,KAAKG,IAAI,CAACC,YAAY,CAACG,aAAa;gBACzF;gBACAS,MAAM;oBACJd;oBACAI;oBACAW,WAAWf,aAAaI;oBACxB3D,UAAU;gBACZ;gBACAuE,cAAc,IAAI,CAACC,eAAe,CAACO,WAAWN,aAAa;YAC7D;QACF,EAAE,OAAOC,OAAO;YACdxB,aAAaV;YACb,MAAM,IAAI,CAACmC,cAAc,CAACD;QAC5B;IACF;IAEA,OAAiBO,iBAAiB1E,OAAmB,EAAiC;QACpF,MAAMC,SAASD,QAAQE,QAAQ,CAACC,MAAM,GAAG,KAAKH,QAAQE,QAAQ,CAAC,EAAE,CAACE,IAAI,KAAK;QAC3E,MAAMC,QAAQL,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;QAEhD,IAAIJ,UAAUI,MAAMC,UAAU,CAAC,YAAY;YACzC,OAAO,IAAI,CAACqE,kBAAkB,CAAC3E;QACjC,OAAO;YACL,OAAO,IAAI,CAAC4E,sBAAsB,CAAC5E;QACrC;IACF;IAEA,OAAe2E,mBAAmB3E,OAAmB,EAAiC;QACpF,MAAME,WAAW,IAAI,CAACO,eAAe,CAACT,QAAQE,QAAQ;QACtD,MAAMQ,gBAAgBV,QAAQE,QAAQ,CAACS,IAAI,CAACC,CAAAA,IAAKA,EAAER,IAAI,KAAK;QAE5D,MAAMS,gBAAgB;YACpBR,OAAO,IAAI,CAACS,gBAAgB,CAACd,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK;YAC/DH;YACAa,UAAUL,eAAeM;YACzBC,aAAajB,QAAQiB,WAAW,IAAI,IAAI,CAACpB,MAAM,CAACoB,WAAW;YAC3DC,YAAYlB,QAAQmB,SAAS,IAAI,IAAI,CAACtB,MAAM,CAACsB,SAAS;YACtDC,GAAGpB,QAAQqB,IAAI,IAAI,IAAI,CAACxB,MAAM,CAACwB,IAAI;YACnCC,GAAGtB,QAAQuB,IAAI,IAAI,IAAI,CAAC1B,MAAM,CAAC0B,IAAI;YACnCC,mBAAmBxB,QAAQyB,gBAAgB,IAAI,IAAI,CAAC5B,MAAM,CAAC4B,gBAAgB;YAC3EC,kBAAkB1B,QAAQ2B,eAAe,IAAI,IAAI,CAAC9B,MAAM,CAAC8B,eAAe;YACxEC,gBAAgB5B,QAAQ6B,aAAa,IAAI,IAAI,CAAChC,MAAM,CAACgC,aAAa;YAClEC,QAAQ;QACV;QAEA,MAAMC,aAAa,IAAIC;QACvB,MAAMC,UAAUC,WAAW,IAAMH,WAAWI,KAAK,IAAI,AAAC,CAAA,IAAI,CAACtC,MAAM,CAACoC,OAAO,IAAI,KAAI,IAAK;QAEtF,IAAI;YACF,MAAMG,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,KAAK,CAAC,EAAE;gBACnD4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;gBACrB4C,MAAMC,KAAKC,SAAS,CAAC5B;gBACrB6B,QAAQX,WAAWW,MAAM;YAC3B;YAEA,IAAI,CAACN,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI,CAACC,mBAAmB,CAACT;YACjC;YAEA,MAAMyC,SAASzC,SAASG,IAAI,CAAEuC,SAAS;YACvC,MAAMC,UAAU,IAAIC;YACpB,IAAIC,SAAS;YACb,IAAIC,eAAe;YAEnB,MAAO,KAAM;gBACX,MAAM,EAAEC,IAAI,EAAEC,KAAK,EAAE,GAAG,MAAMP,OAAOQ,IAAI;gBACzC,IAAIF,MAAM;gBAEVF,UAAUF,QAAQO,MAAM,CAACF,OAAO;oBAAEtD,QAAQ;gBAAK;gBAC/C,MAAMyD,QAAQN,OAAOO,KAAK,CAAC;gBAC3BP,SAASM,MAAME,GAAG,MAAM;gBAExB,KAAK,MAAMC,QAAQH,MAAO;oBACxB,IAAIG,KAAKC,IAAI,OAAO,IAAI;oBAExB,IAAI;wBACF,MAAM7C,OAAON,KAAKoD,KAAK,CAACF;wBAExB,IAAI5C,KAAKW,IAAI,EAAE;4BACbyB,gBAAgBpC,KAAKW,IAAI;4BACzB,MAAM;gCACJoC,MAAM;gCACNC,OAAO;oCAAE9E,SAAS8B,KAAKW,IAAI;gCAAC;4BAC9B;wBACF;wBAEA,IAAIX,KAAKiD,WAAW,EAAE;4BAEpB,MAAMpC,eAAe,IAAI,CAACqC,cAAc,CAACxD,KAAKC,SAAS,CAACzC,QAAQE,QAAQ;4BACxE,MAAM0D,mBAAmB,IAAI,CAACoC,cAAc,CAACd;4BAE7C,MAAM5F,UAAU,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACU,QAAQK,KAAK,IAAI,IAAI,CAACR,MAAM,CAACQ,KAAK,CAAC;4BAC9E,MAAM2C,aAAa,AAACW,eAAe,OAAQrE,QAAQC,eAAe;4BAClE,MAAM6D,iBAAiB,AAACQ,mBAAmB,OAAQtE,QAAQE,mBAAmB;4BAE9E,MAAM;gCACJqG,MAAM;gCACNnC,OAAO;oCACLC;oCACAC;oCACAC,aAAaF,eAAeC;gCAC9B;gCACAE,MAAM;oCACJd;oCACAI;oCACAW,WAAWf,aAAaI;oCACxB3D,UAAU;gCACZ;4BACF;wBACF;oBACF,EAAE,OAAOwG,GAAG;wBACV,IAAI,CAACC,MAAM,CAACC,IAAI,CAAC,uCAAuC;4BAAET;4BAAMvB,OAAO8B;wBAAE;oBAC3E;gBACF;YACF;QACF,EAAE,OAAO9B,OAAO;YACdxB,aAAaV;YACb,MAAM,IAAI,CAACmC,cAAc,CAACD;QAC5B,SAAU;YACRxB,aAAaV;QACf;IACF;IAEA,OAAe2C,uBAAuB5E,OAAmB,EAAiC;QAGxF,OAAO,IAAI,CAAC2E,kBAAkB,CAAC3E;IACjC;IAEA,MAAMoG,aAAkC;QACtC,OAAO,IAAI,CAAChI,YAAY,CAACC,eAAe;IAC1C;IAEA,MAAMgI,aAAahG,KAAe,EAAsB;QACtD,OAAO;YACLA;YACAlC,MAAMkC;YACNiG,aAAa,IAAI,CAACC,mBAAmB,CAAClG;YACtCmG,eAAe,IAAI,CAACpI,YAAY,CAACE,gBAAgB,CAAC+B,MAAM,IAAI;YAC5D9B,iBAAiB,IAAI,CAACH,YAAY,CAACG,eAAe,CAAC8B,MAAM,IAAI;YAC7DoG,mBAAmB;gBACjB;gBACA;gBACA;mBACIpG,MAAMC,UAAU,CAAC,aAAa;oBAAC;iBAAQ,GAAG,EAAE;aACjD;YACDhB,SAAS,IAAI,CAAClB,YAAY,CAACkB,OAAO,AAAC,CAACe,MAAM;QAC5C;IACF;IAEA,MAAgBqG,gBAA4C;QAC1D,IAAI;YACF,MAAMtE,WAAW,MAAMC,MAAM,GAAG,IAAI,CAAC3C,OAAO,CAAC,cAAc,CAAC,EAAE;gBAC5D4C,QAAQ;gBACR3C,SAAS,IAAI,CAACA,OAAO;YACvB;YAEA,IAAI,CAACyC,SAASQ,EAAE,EAAE;gBAChB,MAAM,IAAI+D,MAAM,CAAC,qBAAqB,EAAEvE,SAASwE,MAAM,EAAE;YAC3D;YAEA,OAAO;gBACLC,SAAS;gBACTC,WAAW,IAAIC;YACjB;QACF,EAAE,OAAO5C,OAAO;YACd,OAAO;gBACL0C,SAAS;gBACT1C,OAAOA,iBAAiBwC,QAAQxC,MAAM6C,OAAO,GAAG;gBAChDF,WAAW,IAAIC;YACjB;QACF;IACF;IAEQtG,gBAAgBP,QAAgC,EAAE;QACxD,OAAOA,SACJ+G,MAAM,CAACrG,CAAAA,IAAKA,EAAER,IAAI,KAAK,UACvBkE,GAAG,CAAC1D,CAAAA,IAAM,CAAA;gBACTR,MAAMQ,EAAER,IAAI,KAAK,cAAc,YAAqB;gBACpD4G,SAASpG,EAAEI,OAAO;YACpB,CAAA;IACJ;IAEQF,iBAAiBT,KAAe,EAAU;QAChD,MAAM6G,WAAmC;YACvC,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACA,OAAOA,QAAQ,CAAC7G,MAAM,IAAIA;IAC5B;IAEQ4D,gBAAgBkD,MAAc,EAAqB;QACzD,OAAOA,WAAW,aAAa,SAAS;IAC1C;IAEQZ,oBAAoBlG,KAAe,EAAU;QACnD,MAAM+G,eAAuC;YAC3C,WAAW;YACX,iBAAiB;YACjB,mBAAmB;YACnB,mBAAmB;YACnB,mBAAmB;QACrB;QACA,OAAOA,YAAY,CAAC/G,MAAM,IAAI;IAChC;IAEA,MAAcwC,oBAAoBT,QAAkB,EAAiB;QACnE,MAAMiF,YAAY,MAAMjF,SAASqB,IAAI;QACrC,IAAI6D;QAEJ,IAAI;YACFA,YAAY9E,KAAKoD,KAAK,CAACyB;QACzB,EAAE,OAAM;YACNC,YAAY;gBAAEN,SAASK;YAAU;QACnC;QAEA,MAAML,UAAUM,UAAUN,OAAO,IAAI;QAErC,OAAQ5E,SAASwE,MAAM;YACrB,KAAK;gBACH,MAAM,IAAI3I,oBAAoB+I,SAAS,UAAUM;YACnD,KAAK;gBACH,MAAM,IAAItJ,eAAegJ,SAAS,UAAUO,WAAWD;YACzD;gBACE,MAAM,IAAIvJ,iBACRiJ,SACA,CAAC,OAAO,EAAE5E,SAASwE,MAAM,EAAE,EAC3B,UACAxE,SAASwE,MAAM,EACfxE,SAASwE,MAAM,IAAI,KACnBU;QAEN;IACF;AACF"}